<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Denoising Diffusion Probabilistic Models – Addisu Amare</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-1db3f541d99483cdc7a0d9cf38862b2c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../css/styles.css">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Addisu Amare</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../research.html"> 
<span class="menu-text">Scholarship</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../documents.html"> 
<span class="menu-text">Article</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../project.html"> 
<span class="menu-text">projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../Hobbies.html"> 
<span class="menu-text">My Hobbies</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../Jupyter_note_book.html"> 
<span class="menu-text">Cancer classification</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/Addisu-Amare"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Denoising Diffusion Probabilistic Models</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Author: Addisu Amare</p>
<section id="materials" class="level3">
<h3 class="anchored" data-anchor-id="materials">materials</h3>
<p>paper_1 - https://arxiv.org/pdf/2006.11239.pdf (DDPM)</p>
<p>paper_2 - https://arxiv.org/pdf/1503.03585.pdf(the first paper of diffusion models)</p>
<p>paper_3 - https://arxiv.org/pdf/2011.13456.pdf (for continuous case)</p>
<p>book_1 - https://www.cmor-faculty.rice.edu/~cox/stoch/SDE.course.pdf thoery of stochastic differential equations (for dummies)</p>
<p>book_2 - https://link.springer.com/book/10.1007/978-1-4939-1323-7 (more general)</p>
</section>
<section id="another-view-to-vae-models" class="level2">
<h2 class="anchored" data-anchor-id="another-view-to-vae-models">1. Another view to VAE models</h2>
<p><strong>Questions for the audience</strong></p>
<ul>
<li>What are discriminative models?</li>
<li>What are generative models?</li>
<li>What task do generative models solve?</li>
</ul>
<p>Having defined the main task of generative models, it is logical to ask yourself the question - “How do we actually evaluate the probability of objects from the training sample?”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://learnopencv.com/wp-content/uploads/2020/10/gen_disc_model-1.jpg" class="img-fluid figure-img"></p>
<figcaption>title</figcaption>
</figure>
</div>
<ul>
<li>The principle of maximum likelihood:</li>
</ul>
<p>When we want to train a generative model <span class="math inline">\(p(x|\theta)\)</span>, then the first attempt to do this is the basis for solving the so-called <span class="math inline">\(\textbf{MLE-problem}\)</span> or the problem of maximizing the likelihood of the model by selecting its parameters:</p>
<p><span class="math display">\[\theta = \arg\max_{\theta} \log p(X|\theta) = \{ X = \{ x_{i}\}_{i=1}^{n}\}= \arg\max_{\theta} \sum_{i=1}^{n} \log p(x_{i}|\theta)\]</span></p>
<p><strong>Questions for the audience</strong> Why are we not satisfied with this approach?</p>
<ul>
<li>Latent space:</li>
</ul>
<p>Before we move on to another way of estimating the likelihood of data, we will recall the essence of latent representations. The main intuition of which is shown in the picture below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/r-isachenko/2022-2023-DGM-MIPT-course/blob/main/seminars/seminar3/pics/lvm_diagram.png?raw=true" class="img-fluid figure-img"></p>
<figcaption>title</figcaption>
</figure>
</div>
<ul>
<li>Models of the variation encoder:</li>
</ul>
<p>Another attempt to assess the likelihood is to introduce latent variables and consider the VAE model. When we are dealing with a variational autoencoder, we do not have access to an honest value of the logarithm of likelihood, so we optimize the corresponding lower bound, which we call as <span class="math inline">\(\textbf{ELBO}\)</span></p>
<p><span class="math display">\[ \log p(x|\theta) \geq \mathcal{L}(\theta,q) = \int_{Z}q(z|x, \phi)\log\frac{p(x,z|\theta)}{q(z|x,\phi)} dz\]</span></p>
<ul>
<li>Expansion of the latent space: more is better than one</li>
</ul>
<p>We know that the variational autoencoder has exactly one latent space. That is, we entered the latent space with an encoder and <span class="math inline">\(\bf{immediately}\)</span> leave it with the help of a decoder, while we do not explore the latent space in any way.</p>
<p>However, let’s try to expand the number of latent spaces by introducing <span class="math inline">\(T\)</span> consecutive latent spaces with corresponding decompositions of <span class="math inline">\(f_{i}\)</span>. That is, we use the encoder to move into the latent space and walk through the latent space for a certain number of steps</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://images.velog.io/images/dbj2000/post/18dec128-e2da-45e0-9594-858e6335bab8/VAE.png" class="img-fluid figure-img"></p>
<figcaption>title</figcaption>
</figure>
</div>
</section>
<section id="hierarchical-vae-models" class="level2">
<h2 class="anchored" data-anchor-id="hierarchical-vae-models">2. Hierarchical VAE models</h2>
<p>For the simplicity, let me denote the follwoing:</p>
<ul>
<li><p>x = <span class="math inline">\(x_{0}\)</span></p></li>
<li><p><span class="math inline">\(z_{1} = x_{1}\)</span></p></li>
<li><p><span class="math inline">\(z_{2} = x_{2}\)</span></p></li>
<li><p><span class="math inline">\(z_{T} = x_{T}\)</span></p></li>
</ul>
<p>After introduction more convinient notation for <span class="math inline">\(T\)</span> dimensional vectors, we should define transfromation functions between <span class="math inline">\(f_{i}\)</span> between latent statements. Undoubtedly, one can consider neural networks for this purpose , however, do not worth to complicate our life</p>
<p><span class="math inline">\(\textbf{Assumption :}\)</span> Let these functions <span class="math inline">\(f_{i}\)</span> are <span class="math inline">\(\textbf{not-learnable}\)</span> certain transfromations. Since we would like to add some stochasticity to the framework, one can consider fixed distributions as such transformations:</p>
<p><span class="math display">\[ q(x_{t}|x_{t_1}) = \mathcal{N}(x_{t}| x_{t-1}, \beta I) \]</span></p>
<p>Now, our method looks like <span class="math inline">\(\textbf{Brownian motion}\)</span> or <span class="math inline">\(\textbf{Random movements}\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/VAE_Basic.png/640px-VAE_Basic.png" class="img-fluid figure-img"></p>
<figcaption>title</figcaption>
</figure>
</div>
<p>However, if we will learn means of such transformations (normal distributions) , then we obtain method that is referred to as <span class="math inline">\(\textbf{Hierarchical VAE}\)</span>. Please, see this <span class="math inline">\(\href{https://jmtomczak.github.io/blog/9/9_hierarchical_lvm_p1.html}{blog}\)</span> for best understanding of this concept</p>
<p>Thus, thanks to this copncept, we realize that one can whole latent spaces <span class="math inline">\(Z = \{ x_{1},...,x_{T}\}\)</span> and then the corresponding <span class="math inline">\(\textbf{ELBO}\)</span> formula is:</p>
<p><span class="math display">\[ \log p(x|\theta) \geq \mathcal{L}(\theta,q) = \int_{Z}q(x_{1},...,x_{T}|x_{0}, \phi)\log\frac{p(x_{0},x_{1},..,x_{T}|\theta)}{q(x_{1},...,x_{T}|x_{0},\phi)} dx_{1:T}\]</span></p>
</section>
<section id="gaussian-diffusion-processes" class="level2">
<h2 class="anchored" data-anchor-id="gaussian-diffusion-processes">3. Gaussian diffusion processes</h2>
</section>
<section id="question-motivation" class="level1">
<h1>Question (Motivation):</h1>
<section id="what-is-the-main-motivation-to-consider-many-steps-in-latent-space" class="level2">
<h2 class="anchored" data-anchor-id="what-is-the-main-motivation-to-consider-many-steps-in-latent-space">1. What is the main motivation to consider many steps in latent space?</h2>
<pre><code> - answer is here</code></pre>
</section>
<section id="what-components-do-lie-at-the-heart-of-the-loss-function-of-vae" class="level2">
<h2 class="anchored" data-anchor-id="what-components-do-lie-at-the-heart-of-the-loss-function-of-vae">2. What components do lie at the heart of the loss function of VAE?</h2>
<pre><code> - answer is here</code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://user-images.githubusercontent.com/15643651/64048117-65e9bb80-cb36-11e9-8564-00aacc8ad4e9.png" class="img-fluid figure-img"></p>
<figcaption>title</figcaption>
</figure>
</div>
<p>Because the quality of generation of the hierarchical model of the variation encoder is better than the usual one.</p>
<p><strong>A question to the audience</strong></p>
<ul>
<li>then what conclusion does the number of latent representations suggest?</li>
</ul>
<p>Then we realize that the more latent spaces we consider, the better and better the quality of the model.</p>
<p>Then the question arises - “But if you take a lot of such latent representations, what will happen?”</p>
<p>And answering this question, let’s slightly correct our transitional density of the hierarchical model of the variation encoder:</p>
<p><span class="math display">\[ q(x_t | x_{t-1}) = \mathcal{N}(x_t | x_{t-1}, \beta I) \to q(x_t | x_{t-1}) = \mathcal{N}(x_t | \sqrt{1-\beta}x_{t-1}, \beta I)\]</span></p>
<p>Then it turns out that such a transient density determines the Markov process (where the present <span class="math inline">\(x_{t}\)</span> depends only on the past <span class="math inline">\(x_{t-1}\)</span>):</p>
<p><span class="math display">\[ x_t = \sqrt{1 - \beta} x_{t-1} + \sqrt{\beta} \epsilon \]</span></p>
<p>where $ $ is usually a standard normal random variable</p>
<p>Thus, our transition process between latent spaces is a Markov process, and here’s what’s interesting to say about it:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://static.wikia.nocookie.net/carl-gauss/images/9/9b/Carl_Friedrich_Gauss.jpg/revision/latest?cb=20131217062401.png" class="img-fluid figure-img"></p>
<figcaption>title</figcaption>
</figure>
</div>
<section id="theorem-1" class="level3">
<h3 class="anchored" data-anchor-id="theorem-1">Theorem 1:</h3>
<section id="given" class="level4">
<h4 class="anchored" data-anchor-id="given">Given:</h4>
<ul>
<li>$ x_0 (x) $</li>
<li>$(0,1) $</li>
</ul>
<ol type="1">
<li><p>Then applying the Markov chain to an arbitrary distribution of <span class="math inline">\(\pi(x)\)</span>infinitely many times, we get <span class="math inline">\(\mathcal{N}(0,I)\)</span>. Thus, <span class="math inline">\(\mathcal{N}(0,I)\)</span> is a stationary distribution of the chain. That is, the following condition will be fulfilled $ p_(x) = (0, I) = q(x |x’) p_(x’) dx’ $</p></li>
<li><p>If we denote $ <em>t =</em>{s=1}^{t} (1 - _s) $. Then we can express the sample of the process at any point in time using:</p></li>
</ol>
<p><span class="math display">\[ x_t = \sqrt{\overline{\alpha}_t} x_0 + \sqrt{1 - \overline{\alpha}_t} \epsilon \]</span></p>
<p><span class="math display">\[ q(x_t | x_0) = \mathcal{N}(x_t | \sqrt{\overline{\alpha}_t} x_0, (1 - \overline{\alpha}_t) I) \]</span></p>
<p>This means that we can select any <span class="math inline">\(x_t\)</span> using only <span class="math inline">\(x_0\)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://learnopencv.com/wp-content/uploads/2023/02/denoising-diffusion-probabilistic-models_forward_process_changing_distribution.png" title="chess" class="img-fluid figure-img"></p>
<figcaption>ChessUrl</figcaption>
</figure>
</div>
<p><span class="math inline">\(\textbf{The essence of theorem 1}\)</span></p>
<ol type="1">
<li><p>The Markov process that we are considering will transform any data distribution into a normal standard distribution in an infinitely long time</p></li>
<li><p>The process is the so-called <span class="math inline">\(\textbf{free simulation}\)</span>, that is, taking any point <span class="math inline">\(x_{0}\)</span> and any point in time <span class="math inline">\(t\)</span>, you can instantly find <span class="math inline">\(x_{t}\)</span></p></li>
</ol>
<p>We have proved the existence of a stochastic transformation <strong>from data to noise</strong>.</p>
<p>Remember that the diffusion process does not depend on the initial density of <span class="math inline">\(\pi(x)\)</span>(complex) and the only requirement is access to a sample from it. The main idea of diffusion models is to use any data distribution of our choice as a complex initial density and gradually noise them. Thus, we understand the <strong>direct diffusion process</strong> as:</p>
<p><span class="math display">\[ x_{0} \sim p_{data}(x) \implies \mathcal{F}(x_{0}) = x_{T} : x_{T} \sim \mathcal{N}(0,I) \]</span></p>
<p><strong>The idea:</strong> We have an equation for the direct noise reduction process that looks like this:</p>
<p><span class="math display">\[ dx_t = \sqrt{1 - \beta_t} x_{t-1} + \sqrt{\beta} \epsilon \]</span></p>
<p>Thanks to this equation, you can construct <span class="math inline">\(\color{red}{\textbf{!! Untrained !!}}\)</span> trajectory <strong>from data to noise</strong>.</p>
<p>If we are dealing with an ordinary differential equation (ODE), then we can run this ODE in reverse time and get trajectories from noise to data. However, our process is not defined by an ODE, but by some kind of complex Stochastic diff equation. And this means that I would like to learn how to unfold such random equations in time.</p>
<p><strong>Motivation for learning diffusion models</strong></p>
<ul>
<li>There is a process from data to noise</li>
<li>I want to expand the process</li>
<li>The detailed process goes from noise to data</li>
</ul>
<p>Also, one can compare architectures and concepts of another generative models:</p>
<ul>
<li>VAE</li>
<li>FLOW-based models</li>
<li>Diffusion models</li>
<li>GAN</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://avatars.mds.yandex.net/i?id=3634834bc3bcc017e59b06dc757a782e_l-9036873-images-thumbs&amp;n=13.png" title="chess" class="img-fluid figure-img"></p>
<figcaption>ChessUrl</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="reverse-process" class="level2">
<h2 class="anchored" data-anchor-id="reverse-process">4. Reverse process</h2>
<p><span class="math inline">\(\textbf{Theoretical statetment:}\)</span> If forward process is represented as set of Gaussian condtional transfromtions <span class="math inline">\(q(x_{t}|x_{t-1})\)</span>, then the reverse process will be the same, but with unknown parameters <span class="math inline">\(p{x_{t-1}|x_{t}}\)</span></p>
<p>Thus, we have 2 joint distributions of latent codes:</p>
<p>By the property of Markovian chains, one can represent forward process as:</p>
<ul>
<li><span class="math inline">\(q(x_{1},...,x_{T}|x_{0}) = q( x_{T} | x_{T-1},x_{0}) q(x_{T-1} | x_{T-2},x_{0})...q(x_{2} | x_{1},x_{0})\)</span></li>
</ul>
<p>By the property of Markovian chains, one can represent reversed process as:</p>
<ul>
<li><span class="math inline">\(p(x_{1},...,x_{T}) = p(x_{T-1}|x_{T})p(x_{T-1}|x_{T})....p(x_{1}|x_{2})\)</span></li>
</ul>
<p>Now, we pay our attention to the loss function:</p>
<p><span class="math display">\[\int_{x_{1:T}}q(x_{1},...,x_{T}|x_{0})\log\frac{p(x_{0},x_{1},....,x_{T})}{q(x_{1},....,x_{T}|x_{0})}dx_{1: T}\]</span></p>
<p>Thus, one can represent this loss as corresponding KL-divergenges:</p>
<p><span class="math display">\[ \int_{x_{1:T}} q(x_{1},...,x_{T}|x_{0})\log p(x_{0}|x_{1})dx_{1:T} + \int_{x_{1:T}}q(x_{1},...,x_{T}|x_{0})\log\frac{p(x_{1},....,x_{T})}{q(x_{1},....,x_{T}|x_{0})}dx_{1: T} \]</span></p>
<p>Now , we should take into account the second term, that it is similar to minimization of KL-divergences, however, we chains in opposite directions. Then, one can represent forward Markov chains transformation probabilities in opposite direction via <span class="math inline">\(\textbf{Bayes Theorem}\)</span></p>
<p><span class="math inline">\(\textbf{My desire:}\)</span> i would like to represent the forward markov chain as:</p>
<p><span class="math inline">\(q(x_{1},...,x_{T}|x_{0}) = q(x_{T}|x_{0})q(x_{T-1}|x_{T},x_{0})q(x_{T-2}|x_{T-1},x_{0})...q(x_{1}|x_{2},x_{0})\)</span></p>
<p><span class="math inline">\(\textbf{Bayes theorem:}\)</span></p>
<p><span class="math display">\[ q(x_{t-1}|x_{t},x_{0}) = \frac{q(x_{t}|x_{t-1},x_{0})q(x_{t-1}|x_{0})}{q(x_{t}|x_{0})}\]</span></p>
<p>Clarifications:</p>
<ul>
<li><p>I have Markovian process,hence, there is no dependences on $x_{0} q(x_{t}|x_{t-1},x_{0}) q(x_{t}|x_{t-1}) $</p></li>
<li><p>All distributions are gaussian <span class="math inline">\(\implies\)</span> one can perform accurate bayesiam inference</p></li>
</ul>
<p>At home, you can substitute corresponding probabilities and get formula for posterior:</p>
<p><span class="math display">\[q(x_{t-1}|x_{t},x_{0}) = \mathcal{N}(x_{t-1}| \hat{\mu}_{t}(x_{t},x_{0}),\hat{\beta_{t}}I)\]</span></p>
<ul>
<li>Mean:</li>
</ul>
<p><span class="math display">\[\hat{\mu}_{t}(x_{t},x_{0})= \frac{\sqrt{\overline{\alpha}_{t-1}}}{1 - \overline{\alpha_{t}}}\beta x_{0} +\frac{\sqrt{1 - \beta}(1 - \overline{\alpha_{t}} )}{1 - \overline{\alpha_{t}}}x_{t}  \]</span></p>
<ul>
<li>Variance:</li>
</ul>
<p><span class="math display">\[\hat{\beta_{t}} = \beta_{t}(1 - \overline{\alpha_{t-1}}) \frac{1}{1 - \overline{\alpha}_{t}}\]</span></p>
</section>
<section id="the-loss-deriavation" class="level2">
<h2 class="anchored" data-anchor-id="the-loss-deriavation">5. The loss deriavation</h2>
<p>Now, we return to ELBO:</p>
<p><span class="math display">\[ \int q(x_{1}|x_{0}) \log p(x_{0}|x_{1})dx_{1} + \int q(x_{T}|x_{0})...q(x_{1}|x_{2},x_{0})\log \frac{p(x_{1}|x_{2})}{q(x_{1}|x_{2},x_{0})}
\frac{p(x_{T-1}|x_{T})}{q(x_{T-1}|x_{T},x_{0})}\frac{....}{....} \frac{p(x_{T})}{q(x_{T}|x_{0})}\]</span></p>
<p>Then:</p>
<p><span class="math display">\[ - \sum_{t=1}^{T} \mathbb{E}_{x_{1},..,x_{T}} KL(q(x_{t-1}|x_{t},x_{0}) || p(x_{t-1}|x_{t}))) - KL(q(x_{T}|x_{0}||p(x_{T})) + \int q(x_{1}|x_{0}) \log p(x_{0}|x_{1})dx_{1}\]</span></p>
<ul>
<li><p>If <span class="math inline">\(x_{1} \approx x_{0}\)</span>, then const</p></li>
<li><p>As for certain KL in terminate state ?</p></li>
</ul>
<p><span class="math inline">\(\textbf{Idea}\)</span>: Minimization of KL divergences</p>
<ul>
<li><p>for simplicity: <span class="math inline">\(p_{\theta}(x_{t-1}|x_{t}) = \mathcal{N}(\mu_{\theta}(x_{t},t),\hat{\beta_{t}}I)\)</span></p></li>
<li><p>Mean matching:</p></li>
</ul>
<p><span class="math display">\[ KL(q(x_{t-1}|x_{t},x_{0})|| p_{\theta}(x_{t-1}|x_{t})) = \mathbb{E}_{x_{0},x_{1},...,x_{T},t}\frac{1}{2\hat{\beta_{t}}}|| \hat{\mu}_{t}(x_{t},x_{0}) - \mu_{\theta}(x_{t},t)||_{2}^{2}\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://avatars.mds.yandex.net/i?id=f4d7440eda7d238ddfc0b89f1e6f31dfa1f8490d-10547508-images-thumbs&amp;n=13.png" title="chess" class="img-fluid figure-img"></p>
<figcaption>ChessUrl</figcaption>
</figure>
</div>
</section>
<section id="re-parameterization-like-simplification" class="level2">
<h2 class="anchored" data-anchor-id="re-parameterization-like-simplification">6. Re-parameterization like simplification</h2>
<p>We would like to approximate <span class="math inline">\(\mu_{\theta}\)</span> by <span class="math inline">\(\hat{\mu_{t}}\)</span>, but there is the problem! <span class="math inline">\(\hat{\mu_{t}}(x_{0})\)</span>, while trainable mean does not depend on <span class="math inline">\(x_{0}\)</span>. As a consequence of that, we cannot converge to 0 this problem:</p>
<p><span class="math inline">\(\textbf{Re-parametrization:}\)</span></p>
<p><span class="math display">\[\hat{\mu}_{t}(x_{t},x_{0})= \frac{\sqrt{\overline{\alpha}_{t-1}}}{1 - \overline{\alpha_{t}}}\beta x_{0} +\frac{\sqrt{1 - \beta}(1 - \overline{\alpha_{t}} )}{1 - \overline{\alpha_{t}}}x_{t}  \]</span></p>
<p><span class="math display">\[ \mu_{theta}(x_{t},t) = \frac{\sqrt{\overline{\alpha}_{t-1}}}{1 - \overline{\alpha_{t}}}\beta \color{red}{x_{\theta}(x_{t},t)} +\frac{\sqrt{1 - \beta}(1 - \overline{\alpha_{t}} )}{1 - \overline{\alpha_{t}}}x_{t} \]</span></p>
<ul>
<li>Red term is as estimatiomn for <span class="math inline">\(x_{0}\)</span></li>
</ul>
<p>Then:</p>
<p><span class="math display">\[\frac{1}{2\hat{\beta}_{t}}||\hat{\mu_{t}}(x_{t},x_{0}) - \mu_{\theta}(x_{t},t)||_{2}^{2}
= \frac{1}{2\hat{\beta}_{t}} || \frac{\sqrt{\overline{\alpha}_{t-1}}}{1-\overline{\alpha_{t}}}\beta (x_{0} - x_{\theta}(x_{t},t))||^{2}_{2}\]</span></p>
<p><span class="math inline">\(\textbf{Final reparamterization:}\)</span></p>
<p><span class="math display">\[ x_{t} = \sqrt{\overline{\alpha}_{t}}x_{0} + \sqrt{1 - \overline{\alpha}_{t}}\hat{\epsilon} \]</span></p>
<p>Then, one can express:</p>
<p><span class="math display">\[x_{0} = \frac{1}{\sqrt{\overline{\alpha_{t}}}}(x_{t} - \sqrt{1 - \overline{\alpha}_{t}}\hat{\epsilon} ) \]</span></p>
<p>The, one can reparametrize predicted value as:</p>
<p><span class="math display">\[x_{\theta} = \frac{1}{\sqrt{\overline{\alpha_{t}}}}(x_{t} - \sqrt{1 - \overline{\alpha}_{t}} \epsilon_{\theta}(x_{t},t) \]</span></p>
<p>Thus, the final loss function:</p>
<p><span class="math display">\[ \mathcal{L}(\theta) = \sum_{i=1}^{n}\sum_{t=2}^{T} \frac{\beta^{2}}{2\hat{\beta}_{t}(1-\beta)(1- \overline{\alpha}_{t})} ||  \frac{x^{i}_{t} - \sqrt{\overline{\alpha}}_{t}x_{0}^{i}}{\sqrt{1-\overline{\alpha}}_{t}} - \epsilon_{\theta}(x^{i}_{t},t) ||\]</span></p>
</section>
<section id="coding-part" class="level2">
<h2 class="anchored" data-anchor-id="coding-part">7. Coding part</h2>
<div id="17184edb" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> init</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> functional <span class="im">as</span> F</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> TensorDataset</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_moons</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">7.1 models</h3>
<p>It is importantly to point out that our neural network will predict <span class="math inline">\(\textbf{noise}\)</span>.</p>
<p>Our model is neural network, that has 2 inputs:</p>
<ul>
<li><span class="math inline">\(x_{t}\)</span> data</li>
<li><span class="math inline">\(t\)</span> time like condition for more accurate prediction noise of <span class="math inline">\(x_{t}\)</span></li>
</ul>
<p>It is worth to notice that we have the same model for each step , we do not train new model for each new step. <span class="math inline">\(\color{red}{One\quad model\quad for\quad all\quad steps!}\)</span></p>
<p>Also, You should understand that <span class="math inline">\(t\)</span> is like a value condition and in order to estimate his influence to corresponding noise as a condition , it would be great to create embeddings of the time by corresponding network below.</p>
<div id="8d0160e9" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SinusoidalEmbedding(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, size: <span class="bu">int</span>, scale: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.size <span class="op">=</span> size</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scale <span class="op">=</span> scale</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">*</span> <span class="va">self</span>.scale</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        half_size <span class="op">=</span> <span class="va">self</span>.size <span class="op">//</span> <span class="dv">2</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> torch.log(torch.Tensor([<span class="fl">10000.0</span>])) <span class="op">/</span> (half_size <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> torch.exp(<span class="op">-</span>emb <span class="op">*</span> torch.arange(half_size))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> x.unsqueeze(<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span> emb.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        emb <span class="op">=</span> torch.cat((torch.sin(emb), torch.cos(emb)), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> emb</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.size</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="8fa015b0" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PositionalEmbedding(nn.Module):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, size: <span class="bu">int</span>, <span class="bu">type</span>: <span class="bu">str</span>, <span class="op">**</span>kwargs):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer <span class="op">=</span> SinusoidalEmbedding(size, <span class="op">**</span>kwargs)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor):</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.layer(x)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="87d5b8a1" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Block(nn.Module):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, size: <span class="bu">int</span>):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ff <span class="op">=</span> nn.Linear(size, size)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act <span class="op">=</span> nn.GELU()</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x: torch.Tensor):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x <span class="op">+</span> <span class="va">self</span>.act(<span class="va">self</span>.ff(x))</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MLP(nn.Module):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">128</span>, hidden_layers: <span class="bu">int</span> <span class="op">=</span> <span class="dv">3</span>, emb_size: <span class="bu">int</span> <span class="op">=</span> <span class="dv">128</span>,</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                 time_emb: <span class="bu">str</span> <span class="op">=</span> <span class="st">"sinusoidal"</span>, input_emb: <span class="bu">str</span> <span class="op">=</span> <span class="st">"sinusoidal"</span>):</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.time_mlp <span class="op">=</span> PositionalEmbedding(emb_size, time_emb)</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_mlp1 <span class="op">=</span> PositionalEmbedding(emb_size, input_emb, scale<span class="op">=</span><span class="fl">25.0</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.input_mlp2 <span class="op">=</span> PositionalEmbedding(emb_size, input_emb, scale<span class="op">=</span><span class="fl">25.0</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        concat_size <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.time_mlp.layer) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>            <span class="bu">len</span>(<span class="va">self</span>.input_mlp1.layer) <span class="op">+</span> <span class="bu">len</span>(<span class="va">self</span>.input_mlp2.layer)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        layers <span class="op">=</span> [nn.Linear(concat_size, hidden_size), nn.GELU()]</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(hidden_layers):</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>            layers.append(Block(hidden_size))</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>        layers.append(nn.Linear(hidden_size, <span class="dv">2</span>))</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.joint_mlp <span class="op">=</span> nn.Sequential(<span class="op">*</span>layers)</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, t):</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        x1_emb <span class="op">=</span> <span class="va">self</span>.input_mlp1(x[:, <span class="dv">0</span>])</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>        x2_emb <span class="op">=</span> <span class="va">self</span>.input_mlp2(x[:, <span class="dv">1</span>])</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>        t_emb <span class="op">=</span> <span class="va">self</span>.time_mlp(t)</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat((x1_emb, x2_emb, t_emb), dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.joint_mlp(x)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="data" class="level3">
<h3 class="anchored" data-anchor-id="data">7.2 Data</h3>
<p>We use simple two moons dataset as data.</p>
<div id="d3dd9d72" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> moons_dataset(n<span class="op">=</span><span class="dv">8000</span>):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    X, _ <span class="op">=</span> make_moons(n_samples<span class="op">=</span>n, random_state<span class="op">=</span><span class="dv">42</span>, noise<span class="op">=</span><span class="fl">0.03</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    X[:, <span class="dv">0</span>] <span class="op">=</span> (X[:, <span class="dv">0</span>] <span class="op">+</span> <span class="fl">0.3</span>) <span class="op">*</span> <span class="dv">2</span> <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    X[:, <span class="dv">1</span>] <span class="op">=</span> (X[:, <span class="dv">1</span>] <span class="op">+</span> <span class="fl">0.3</span>) <span class="op">*</span> <span class="dv">3</span> <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> TensorDataset(torch.from_numpy(X.astype(np.float32)))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="gaussian-diffusion" class="level3">
<h3 class="anchored" data-anchor-id="gaussian-diffusion">7.3 Gaussian Diffusion</h3>
<p>This calss is composed of whole formulas from senimar , please familiari`e you with these formulas accurately.</p>
<ol type="1">
<li>reconstruct x0:</li>
</ol>
<p><span class="math display">\[x_{0} = \frac{1}{\sqrt{\overline{\alpha_{t}}}}(x_{t} - \sqrt{1 - \overline{\alpha}_{t}}\hat{\epsilon} ) \]</span></p>
<ol start="2" type="1">
<li>q posterior:</li>
</ol>
<p><span class="math display">\[\hat{\mu}_{t}(x_{t},x_{0})= \frac{\sqrt{\overline{\alpha}_{t-1}}}{1 - \overline{\alpha_{t}}}\beta x_{0} +\frac{\sqrt{1 - \beta}(1 - \overline{\alpha_{t}} )}{1 - \overline{\alpha_{t}}}x_{t}  \]</span></p>
<ol start="3" type="1">
<li>get_variance:</li>
</ol>
<p><span class="math display">\[\hat{\beta_{t}} = \beta_{t}(1 - \overline{\alpha_{t-1}}) \frac{1}{1 - \overline{\alpha}_{t}}\]</span></p>
<ol start="4" type="1">
<li>step:</li>
</ol>
<ul>
<li>The sampling moments of time to get <span class="math inline">\(x_{t}\)</span></li>
<li>Make the prediction <span class="math inline">\(x_{0}\)</span></li>
<li>Make the prediction for <span class="math inline">\(x_{t-1}\)</span></li>
<li>Calculate noise</li>
<li>Make one step of the backward process</li>
</ul>
<ol start="5" type="1">
<li>add noise:</li>
</ol>
<ul>
<li>The expression noise through <span class="math inline">\(x_{0}\)</span> and <span class="math inline">\(x_{t}\)</span></li>
<li><span class="math inline">\(\hat{\epsilon} =  \sqrt{\overline{\alpha_{t}}}\frac{x_{0}}{\sqrt{1 -\overline{\alpha_{t}}  }} - x_{t}\frac{1}{\sqrt{1- \overline{\alpha_{t}}}}\)</span></li>
</ul>
<div id="67688312" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NoiseScheduler():</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                 num_timesteps<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>                 beta_start<span class="op">=</span><span class="fl">0.0001</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>                 beta_end<span class="op">=</span><span class="fl">0.02</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                 beta_schedule<span class="op">=</span><span class="st">"linear"</span>):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_timesteps <span class="op">=</span> num_timesteps</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> beta_schedule <span class="op">==</span> <span class="st">"linear"</span>:</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.betas <span class="op">=</span> torch.linspace(</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>                beta_start, beta_end, num_timesteps, dtype<span class="op">=</span>torch.float32)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> beta_schedule <span class="op">==</span> <span class="st">"quadratic"</span>:</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.betas <span class="op">=</span> torch.linspace(</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>                beta_start <span class="op">**</span> <span class="fl">0.5</span>, beta_end <span class="op">**</span> <span class="fl">0.5</span>, num_timesteps, dtype<span class="op">=</span>torch.float32) <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alphas <span class="op">=</span> <span class="fl">1.0</span> <span class="op">-</span> <span class="va">self</span>.betas</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alphas_cumprod <span class="op">=</span> torch.cumprod(<span class="va">self</span>.alphas, axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alphas_cumprod_prev <span class="op">=</span> F.pad(</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.alphas_cumprod[:<span class="op">-</span><span class="dv">1</span>], (<span class="dv">1</span>, <span class="dv">0</span>), value<span class="op">=</span><span class="fl">1.</span>)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># required for self.add_noise</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sqrt_alphas_cumprod <span class="op">=</span> <span class="va">self</span>.alphas_cumprod <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sqrt_one_minus_alphas_cumprod <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod) <span class="op">**</span> <span class="fl">0.5</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># required for reconstruct_x0</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sqrt_inv_alphas_cumprod <span class="op">=</span> torch.sqrt(<span class="dv">1</span> <span class="op">/</span> <span class="va">self</span>.alphas_cumprod)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sqrt_inv_alphas_cumprod_minus_one <span class="op">=</span> torch.sqrt(</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>            <span class="dv">1</span> <span class="op">/</span> <span class="va">self</span>.alphas_cumprod <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># required for q_posterior</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_mean_coef1 <span class="op">=</span> <span class="va">self</span>.betas <span class="op">*</span> torch.sqrt(<span class="va">self</span>.alphas_cumprod_prev) <span class="op">/</span> (<span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod)</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.posterior_mean_coef2 <span class="op">=</span> (<span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod_prev) <span class="op">*</span> torch.sqrt(<span class="va">self</span>.alphas) <span class="op">/</span> (<span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod)</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reconstruct_x0(<span class="va">self</span>, x_t, t, noise):</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>        s1 <span class="op">=</span> <span class="va">self</span>.sqrt_inv_alphas_cumprod[t]</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>        s2 <span class="op">=</span> <span class="va">self</span>.sqrt_inv_alphas_cumprod_minus_one[t]</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a>        s1 <span class="op">=</span> s1.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>        s2 <span class="op">=</span> s2.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> s1 <span class="op">*</span> x_t <span class="op">-</span> s2 <span class="op">*</span> noise</span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> q_posterior(<span class="va">self</span>, x_0, x_t, t):</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>        s1 <span class="op">=</span> <span class="va">self</span>.posterior_mean_coef1[t]</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>        s2 <span class="op">=</span> <span class="va">self</span>.posterior_mean_coef2[t]</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>        s1 <span class="op">=</span> s1.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>        s2 <span class="op">=</span> s2.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>        mu <span class="op">=</span> s1 <span class="op">*</span> x_0 <span class="op">+</span> s2 <span class="op">*</span> x_t</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mu</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_variance(<span class="va">self</span>, t):</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>        variance <span class="op">=</span> <span class="va">self</span>.betas[t] <span class="op">*</span> (<span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod_prev[t]) <span class="op">/</span> (<span class="fl">1.</span> <span class="op">-</span> <span class="va">self</span>.alphas_cumprod[t])</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>        variance <span class="op">=</span> variance.clip(<span class="fl">1e-20</span>)</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> variance</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>, model_output, timestep, sample):</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> timestep</span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>        pred_original_sample <span class="op">=</span> <span class="va">self</span>.reconstruct_x0(sample, t, model_output)</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>        pred_prev_sample <span class="op">=</span> <span class="va">self</span>.q_posterior(pred_original_sample, sample, t)</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>        variance <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>            noise <span class="op">=</span> torch.randn_like(model_output)</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a>            variance <span class="op">=</span> (<span class="va">self</span>.get_variance(t) <span class="op">**</span> <span class="fl">0.5</span>) <span class="op">*</span> noise</span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>        pred_prev_sample <span class="op">=</span> pred_prev_sample <span class="op">+</span> variance</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pred_prev_sample</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_noise(<span class="va">self</span>, x_start, x_noise, timesteps):</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>        s1 <span class="op">=</span> <span class="va">self</span>.sqrt_alphas_cumprod[timesteps]</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>        s2 <span class="op">=</span> <span class="va">self</span>.sqrt_one_minus_alphas_cumprod[timesteps]</span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>        s1 <span class="op">=</span> s1.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>        s2 <span class="op">=</span> s2.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> s1 <span class="op">*</span> x_start <span class="op">+</span> s2 <span class="op">*</span> x_noise</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.num_timesteps</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="training" class="level3">
<h3 class="anchored" data-anchor-id="training">7.4 Training</h3>
<p>We choose hyper parameters for method and run it</p>
<div id="8d0ce042" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>NUM_SAMPLES_DATA <span class="op">=</span> <span class="dv">10_000</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE<span class="op">=</span><span class="dv">128</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>HIDDEN_SIZE <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>HIDDEN_LAYERS<span class="op">=</span><span class="dv">3</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>EMBEDDING_SIZE <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>TIME_EMBEDDING<span class="op">=</span><span class="st">"sinusoidal"</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>INPUT_EMEDDING<span class="op">=</span><span class="st">"sinusoidal"</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>NUM_TIMESTEPS <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>BETA_SCHEDULE <span class="op">=</span> <span class="st">'linear'</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>LR <span class="op">=</span> <span class="fl">5e-4</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>NUM_EPOCHS<span class="op">=</span><span class="dv">200</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="28f4de92" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> moons_dataset(NUM_SAMPLES_DATA)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>dataloader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        dataset, batch_size<span class="op">=</span>BATCH_SIZE , shuffle<span class="op">=</span><span class="va">True</span>, drop_last<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> MLP(</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        hidden_size<span class="op">=</span>HIDDEN_SIZE,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        hidden_layers<span class="op">=</span>HIDDEN_LAYERS,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        emb_size<span class="op">=</span>EMBEDDING_SIZE,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        time_emb<span class="op">=</span>TIME_EMBEDDING,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        input_emb<span class="op">=</span>INPUT_EMEDDING)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>noise_scheduler <span class="op">=</span> NoiseScheduler(</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        num_timesteps<span class="op">=</span>NUM_TIMESTEPS,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        beta_schedule<span class="op">=</span>BETA_SCHEDULE)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        model.parameters(),</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        lr<span class="op">=</span>LR,</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="2fd0ecad" class="cell" data-outputid="32145014-6206-4096-a87a-71fc93117a65" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>global_step <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>frames <span class="op">=</span> []</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>losses <span class="op">=</span> []</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> tqdm(<span class="bu">range</span>(NUM_EPOCHS)):</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> step, batch <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> batch[<span class="dv">0</span>]</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> torch.randn(batch.shape)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        timesteps <span class="op">=</span> torch.randint(a</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>            <span class="dv">0</span>, noise_scheduler.num_timesteps, (batch.shape[<span class="dv">0</span>],)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        ).<span class="bu">long</span>()</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        noisy <span class="op">=</span> noise_scheduler.add_noise(batch, noise, timesteps)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        noise_pred <span class="op">=</span> model(noisy, timesteps)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> F.mse_loss(noise_pred, noise)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        loss.backward(loss)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        nn.utils.clip_grad_norm_(model.parameters(), <span class="fl">1.0</span>)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        optimizer.step()</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        losses.append(loss.detach().item())</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 200/200 [02:07&lt;00:00,  1.56it/s]</code></pre>
</div>
</div>
<div id="43a793e2" class="cell" data-outputid="cec9d7ba-d6c9-46e9-9f93-a413d2850c20" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> torch.randn(<span class="dv">1024</span>, <span class="dv">2</span>) <span class="co"># sampling from noise</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>timesteps <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(noise_scheduler)))[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(timesteps)):</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.from_numpy(np.repeat(t,  <span class="dv">1024</span>)).<span class="bu">long</span>()</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        residual <span class="op">=</span> model(sample, t)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> noise_scheduler.step(residual, t[<span class="dv">0</span>], sample)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:00&lt;00:00, 104.94it/s]</code></pre>
</div>
</div>
<div id="06bf353c" class="cell" data-outputid="563f05f7-f00c-4698-bad9-c19f50f1fcad" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}}">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(sample[:,<span class="dv">0</span>],sample[:,<span class="dv">1</span>], edgecolor<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">"generated data"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>plt.grid()<span class="op">;</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>plt.legend()<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="DDPM_eng_files/figure-html/cell-12-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="8a22de3a" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}}" data-outputid="af116a8b-7e5c-4a82-bb54-6be95c6c55c1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>traj <span class="op">=</span> []</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>sample <span class="op">=</span> torch.randn(<span class="dv">1024</span>, <span class="dv">2</span>) <span class="co"># sampling from noise</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>timesteps <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="bu">len</span>(noise_scheduler)))[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(timesteps)):</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.from_numpy(np.repeat(t,  <span class="dv">1024</span>)).<span class="bu">long</span>()</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        residual <span class="op">=</span> model(sample, t)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    sample <span class="op">=</span> noise_scheduler.step(residual, t[<span class="dv">0</span>], sample)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> t[<span class="dv">0</span>].item() <span class="op">%</span> <span class="dv">5</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>        traj.append(sample.cpu())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>100%|██████████| 50/50 [00:00&lt;00:00, 118.63it/s]</code></pre>
</div>
</div>
<div id="a4db8186" class="cell" data-quarto-private-1="{&quot;key&quot;:&quot;colab&quot;,&quot;value&quot;:{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:204}}" data-outputid="cb2fce13-6eed-4312-ed7d-4a41b8e7fb90">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>fig,ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">10</span>,figsize<span class="op">=</span>(<span class="dv">40</span>,<span class="dv">4</span>),dpi<span class="op">=</span><span class="dv">200</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    ax[idx].scatter(traj[<span class="dv">9</span><span class="op">-</span>idx][:,<span class="dv">0</span>],traj[<span class="dv">9</span><span class="op">-</span>idx][:,<span class="dv">1</span>],edgecolor<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    ax[idx].set_xticks([])<span class="op">;</span>ax[idx].set_yticks([])</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    ax[idx].grid()<span class="op">;</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>fig.tight_layout(pad<span class="op">=</span><span class="fl">0.01</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="DDPM_eng_files/figure-html/cell-14-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="output" class="level1">
<h1>Output</h1>
<ul>
<li>We realized that hierarchical VAE models are better than standard ones</li>
<li>If a deterministic defined transition is applied many times , then any data degrades into noise</li>
<li>Understood as the basis of the direct process , set the reverse</li>
<li>Learned the reverse process</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>
---
title: Breast Cancer  classification Using Machine Learning Classifier
jupyter: python3
---



# Import libraries 

```{python}
# import libraries
import pandas as pd # for data manupulation or analysis
import numpy as np # for numeric calculation
import matplotlib.pyplot as plt # for data visualization
import seaborn as sns # for data visualization
import pickle #for dumping the model or we can use joblib library
```

```{python}
# Suppressing Warnings
import warnings
warnings.filterwarnings('ignore')
```

# Data Load

```{python}
#Load breast cancer dataset
from sklearn.datasets import load_breast_cancer
```

```{python}
# Breast cancer dataset for classification
data = load_breast_cancer()
print (data.feature_names)
print (data.target_names)
```

```{python}
cancer_dataset = load_breast_cancer()
```

# Data Manupulation

```{python}
#| scrolled: true
type(cancer_dataset)
```

```{python}
# keys in dataset
cancer_dataset.keys()
```

```{python}
# target value name malignant or benign tumor
cancer_dataset['target_names']
```

```{python}
#| scrolled: true
# description of data
print(cancer_dataset['DESCR'])
```

```{python}
# name of features
print(cancer_dataset['feature_names'])
```

```{python}
# location/path of data file
print(cancer_dataset['filename'])
```

## Create DataFrame

```{python}
#| scrolled: true
# create datafrmae
cancer_df = pd.DataFrame(np.c_[cancer_dataset['data'],cancer_dataset['target']],
             columns = np.append(cancer_dataset['feature_names'], ['target']))
```

```{python}
# DataFrame to CSV file
cancer_df.to_csv('breast_cancer_dataframe.csv')
```

```{python}
#| scrolled: true
# Head of cancer DataFrame
cancer_df.head(6) 
```

```{python}
#| scrolled: true
# Tail of cancer DataFrame
cancer_df.tail(6) 
```

```{python}
# Information of cancer Dataframe
cancer_df.info()
```

```{python}
#| scrolled: true
# Numerical distribution of data
cancer_df.describe() 
```

```{python}
cancer_df.isnull().sum()
```

# Data Visualization

```{python}
#| scrolled: false
# pair plot of sample feature
sns.pairplot(cancer_df, hue = 'target', 
             vars = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness'] ) # ****** img 5 ***
```

```{python}
# Count the target class
sns.countplot(cancer_df['target']) #  **************************** img 5 *************************  
```

```{python}
#| scrolled: true
# counter plot of feature mean radius
plt.figure(figsize = (20,8))
sns.countplot(cancer_df['mean radius']) # *** img 7 ****
```

##  Heatmap of a correlation matrix 

```{python}
#| scrolled: true
cancer_df.corr()#gives the correlation between them
```

# Correlation Barplot

```{python}
# create second DataFrame by droping target
cancer_df2 = cancer_df.drop(['target'], axis = 1)
print("The shape of 'cancer_df2' is : ", cancer_df2.shape)
```

```{python}
#| scrolled: true
#cancer_df2.corrwith(cancer_df.target)
```

```{python}
cancer_df2.corrwith(cancer_df.target).index
```

# Split DatFrame in Train and Test

```{python}
#| scrolled: true
# input variable
X = cancer_df.drop(['target'], axis = 1) 
X.head(6)
```

```{python}
#| scrolled: true
# output variable
y = cancer_df['target'] 
y.head(6)
```

# split dataset into train and test

```{python}
# split dataset into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 5)
```

```{python}
#| scrolled: true
X_train
```

```{python}
#| scrolled: true
X_test
```

```{python}
#| scrolled: true
y_train
```

```{python}
#| scrolled: true
y_test
```

# Feature scaling 

```{python}
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)
```

# Machine Learning Model Building

```{python}
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
```

## Suppor vector Classifier

```{python}
#| scrolled: true
# Support vector classifier
from sklearn.svm import SVC
svc_classifier = SVC()
svc_classifier.fit(X_train, y_train)
y_pred_scv = svc_classifier.predict(X_test)
accuracy_score(y_test, y_pred_scv)
```

##### Train with Standard scaled Data

```{python}
# Train with Standard scaled Data
svc_classifier2 = SVC()
svc_classifier2.fit(X_train_sc, y_train)
y_pred_svc_sc = svc_classifier2.predict(X_test_sc)
accuracy_score(y_test, y_pred_svc_sc)
```

# Logistic Regression

```{python}
# Logistic Regression
from sklearn.linear_model import LogisticRegression
lr_classifier = LogisticRegression(random_state = 51, C=1, penalty='l1', solver='liblinear')
lr_classifier.fit(X_train, y_train)
y_pred_lr = lr_classifier.predict(X_test)
accuracy_score(y_test, y_pred_lr)
```

#### Train with Standard scaled Data

```{python}
# Train with Standard scaled Data
lr_classifier2 = LogisticRegression(random_state = 51, C=1, penalty='l1', solver='liblinear')
lr_classifier2.fit(X_train_sc, y_train)
y_pred_lr_sc = lr_classifier.predict(X_test_sc)
accuracy_score(y_test, y_pred_lr_sc)
```

# Naive Bayes Classifier

```{python}
# Naive Bayes Classifier
from sklearn.naive_bayes import GaussianNB
nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)
y_pred_nb = nb_classifier.predict(X_test)
accuracy_score(y_test, y_pred_nb)
```

```{python}
# Train with Standard scaled Data
nb_classifier2 = GaussianNB()
nb_classifier2.fit(X_train_sc, y_train)
y_pred_nb_sc = nb_classifier2.predict(X_test_sc)
accuracy_score(y_test, y_pred_nb_sc)
```

# K – Nearest Neighbor Classifier

```{python}
# K – Nearest Neighbor Classifier
from sklearn.neighbors import KNeighborsClassifier
knn_classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
knn_classifier.fit(X_train, y_train)
y_pred_knn = knn_classifier.predict(X_test)
accuracy_score(y_test, y_pred_knn)
```

```{python}
# Train with Standard scaled Data
knn_classifier2 = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
knn_classifier2.fit(X_train_sc, y_train)
y_pred_knn_sc = knn_classifier.predict(X_test_sc)
accuracy_score(y_test, y_pred_knn_sc)
```

# Decision Tree Classifier

```{python}
# Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
dt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)
dt_classifier.fit(X_train, y_train)
y_pred_dt = dt_classifier.predict(X_test)
accuracy_score(y_test, y_pred_dt)
```

```{python}
# Train with Standard scaled Data
dt_classifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 51)
dt_classifier2.fit(X_train_sc, y_train)
y_pred_dt_sc = dt_classifier.predict(X_test_sc)
accuracy_score(y_test, y_pred_dt_sc)
```

 # Random Forest Classifier

```{python}
# Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
rf_classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)
rf_classifier.fit(X_train, y_train)
y_pred_rf = rf_classifier.predict(X_test)
accuracy_score(y_test, y_pred_rf)
```

```{python}
# Train with Standard scaled Data
rf_classifier2 = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)
rf_classifier2.fit(X_train_sc, y_train)
y_pred_rf_sc = rf_classifier.predict(X_test_sc)
accuracy_score(y_test, y_pred_rf_sc)
```

# AdaBoost Classifier

```{python}
# Adaboost Classifier
from sklearn.ensemble import AdaBoostClassifier
adb_classifier = AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = 200),
                                    n_estimators=2000,
                                    learning_rate=0.1,
                                    algorithm='SAMME.R',
                                    random_state=1,)
adb_classifier.fit(X_train, y_train)
y_pred_adb = adb_classifier.predict(X_test)
accuracy_score(y_test, y_pred_adb)
```

```{python}
# Train with Standard scaled Data
adb_classifier2 = AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = 200),
                                    n_estimators=2000,
                                    learning_rate=0.1,
                                    algorithm='SAMME.R',
                                    random_state=1,)
adb_classifier2.fit(X_train_sc, y_train)
y_pred_adb_sc = adb_classifier2.predict(X_test_sc)
accuracy_score(y_test, y_pred_adb_sc)
```













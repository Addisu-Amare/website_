[
  {
    "objectID": "Hobbies.html",
    "href": "Hobbies.html",
    "title": "Addisu Amare",
    "section": "",
    "text": "Hobby\nCategory\nFrequency\nEquipment Needed\n\n\n\n\nCooking\nCreative\nDaily\nKitchen utensils, ingredients\n\n\nReading Novels\nIntellectual\nDaily\nBooks/e-reader\n\n\nFootball\nOutdoor Sport\nWeekly\nCleats, ball, sports gear\n\n\nVolleyball\nTeam Sport\nBi-weekly\nKnee pads, athletic shoes\n\n\n\n\n\n\nCooking - Creative expression and practical life skill\nReading - Mental escape and knowledge expansion\n\nFootball - Physical fitness and teamwork\nVolleyball - Social interaction and coordination"
  },
  {
    "objectID": "Hobbies.html#my-hobbies-at-a-glance",
    "href": "Hobbies.html#my-hobbies-at-a-glance",
    "title": "Addisu Amare",
    "section": "",
    "text": "Hobby\nCategory\nFrequency\nEquipment Needed\n\n\n\n\nCooking\nCreative\nDaily\nKitchen utensils, ingredients\n\n\nReading Novels\nIntellectual\nDaily\nBooks/e-reader\n\n\nFootball\nOutdoor Sport\nWeekly\nCleats, ball, sports gear\n\n\nVolleyball\nTeam Sport\nBi-weekly\nKnee pads, athletic shoes\n\n\n\n\n\n\nCooking - Creative expression and practical life skill\nReading - Mental escape and knowledge expansion\n\nFootball - Physical fitness and teamwork\nVolleyball - Social interaction and coordination"
  },
  {
    "objectID": "documents.html",
    "href": "documents.html",
    "title": "Articles & Projects",
    "section": "",
    "text": "Artificial Intelligence applications in medical imaging analysis.\n\n\nView PDF Download PDF\n\n\n\n\n\n\nFederated learning approaches with explainable AI for medical imaging.\n\n\nView PDF Download PDF\n\n\n\n\n\n\n\n\nAcademic projects and research from undergraduate studies.\n\n\nView PDF Download PDF\n\n\n\n\n\n\nComputer vision and AI-based fire detection system.\n\n\nView PDF Download PDF\n\n\n\n\n\n\n\nOption 1: View in Browser - Click ‚ÄúView PDF‚Äù to open directly in your browser\n\n\nOption 2: Download - Click ‚ÄúDownload PDF‚Äù to save to your device\n\n\nOption 3: GitHub View - All files are accessible via GitHub repository\n\n\n\nNote: All PDFs are hosted on GitHub. For best viewing experience, use Chrome, Firefox, or Edge browsers."
  },
  {
    "objectID": "documents.html#articles",
    "href": "documents.html#articles",
    "title": "Articles & Projects",
    "section": "",
    "text": "Artificial Intelligence applications in medical imaging analysis.\n\n\nView PDF Download PDF\n\n\n\n\n\n\nFederated learning approaches with explainable AI for medical imaging.\n\n\nView PDF Download PDF\n\n\n\n\n\n\n\n\nAcademic projects and research from undergraduate studies.\n\n\nView PDF Download PDF\n\n\n\n\n\n\nComputer vision and AI-based fire detection system.\n\n\nView PDF Download PDF\n\n\n\n\n\n\n\nOption 1: View in Browser - Click ‚ÄúView PDF‚Äù to open directly in your browser\n\n\nOption 2: Download - Click ‚ÄúDownload PDF‚Äù to save to your device\n\n\nOption 3: GitHub View - All files are accessible via GitHub repository\n\n\n\nNote: All PDFs are hosted on GitHub. For best viewing experience, use Chrome, Firefox, or Edge browsers."
  },
  {
    "objectID": "documents.html#projects",
    "href": "documents.html#projects",
    "title": "Articles & Projects",
    "section": "",
    "text": "Academic projects and research from undergraduate studies.\n\n\nView PDF Download PDF\n\n\n\n\n\n\nComputer vision and AI-based fire detection system.\n\n\nView PDF Download PDF\n\n\n\n\n\n\n\nOption 1: View in Browser - Click ‚ÄúView PDF‚Äù to open directly in your browser\n\n\nOption 2: Download - Click ‚ÄúDownload PDF‚Äù to save to your device\n\n\nOption 3: GitHub View - All files are accessible via GitHub repository\n\n\n\nNote: All PDFs are hosted on GitHub. For best viewing experience, use Chrome, Firefox, or Edge browsers."
  },
  {
    "objectID": "documents.html#how-to-view",
    "href": "documents.html#how-to-view",
    "title": "Articles & Projects",
    "section": "",
    "text": "Option 1: View in Browser - Click ‚ÄúView PDF‚Äù to open directly in your browser\n\n\nOption 2: Download - Click ‚ÄúDownload PDF‚Äù to save to your device\n\n\nOption 3: GitHub View - All files are accessible via GitHub repository\n\n\n\nNote: All PDFs are hosted on GitHub. For best viewing experience, use Chrome, Firefox, or Edge browsers."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Introduction: The AI Revolution in Healthcare",
    "section": "",
    "text": "The AI Revolution in Healthcare\n\n\n\nThe Future of Medical Imaging\nMedical imaging is evolving. Artificial intelligence is no longer a simple tool; in fact, it has become part and parcel of diagnostic workflows. There is a growing need for intelligent processing of medical images, which represent approximately 90% of all healthcare data.\n\n\nThe Problem\nRadiologists: Are experiencing a 30-40% increase in workload each year\nImaging technology: High-resolution, 3D and 4D images are becoming more common\nDiagnostic Accuracy: Error rates due to human interpretation can be as high as 30% in some instances\n\n\nHow AI solves these problems\nTwo significant advances have been made with respect to using AI in medical imaging - Convolutional Neural Networks (CNN) have become the standard when it comes to the majority of medical imaging techniques and algorithms.\n\n\n\nüéØ 90%\n\n\nHealthcare data is medical images\n\n\n\n\n‚è±Ô∏è 70%\n\n\nReduction in screening time\n\n\n\n\nüí∞ $4.5B\n\n\nMarket size by 2028\n\n\n\n\nüìà 34%\n\n\nAnnual growth rate\n\n\n\n\n\nWhat You‚Äôll Learn in This Series\n-This comprehensive series explores:\n-CNN applications across various medical specialties\nViT breakthroughs in complex imaging tasks\nReal-world implementations and case studies\nPerformance comparisons and benchmarks\nFuture trends and ethical considerations\nNavigation Guide Next: CNN Overview\nOr jump to: Cancer Detection | Neurology | Ophthalmology"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Below is the course I have taught at the University of Skoltech,Russia during independent period.\n\n\n\nI30202437 Python for Data Science Pseudo-code. Program design and structure. Flow control. Iteration. Lists (arrays). Functions. File I/O. Classes, objects, methods, and libraries."
  },
  {
    "objectID": "teaching.html#courses-taught",
    "href": "teaching.html#courses-taught",
    "title": "Teaching",
    "section": "",
    "text": "Below is the course I have taught at the University of Skoltech,Russia during independent period.\n\n\n\nI30202437 Python for Data Science Pseudo-code. Program design and structure. Flow control. Iteration. Lists (arrays). Functions. File I/O. Classes, objects, methods, and libraries."
  },
  {
    "objectID": "teaching.html#teaching-philosophy",
    "href": "teaching.html#teaching-philosophy",
    "title": "Teaching",
    "section": "Teaching Philosophy",
    "text": "Teaching Philosophy\nI‚Äôve learned that great teaching isn‚Äôt just about delivering content‚Äîit‚Äôs about creating the right conditions for learning to happen. My approach rests on three core pillars: sparking genuine motivation, building a supportive community, and staying flexibly responsive to my students‚Äô needs. When I get these right, I see curiosity catch fire, collaboration flourish, and obstacles to learning start to fall away"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Addisu A. Zena, Btech",
    "section": "",
    "text": "Bio\nAddisu is a technology and biomedical enthusiast who holds a Bachelor‚Äôs degree in Electronics & Communication Engineering (ECE) and Biomedical Engineering from Vellore Institute of Technology (Class of 2022).\nWith a deep interest in programming, data science, and human anatomy and physiology, he continuously works on projects at the intersection of engineering, machine learning, and biomedical research. He is always expanding his skill set through hands-on learning and new technologies.\n###Skills: - Python | MATLAB | LabVIEW\n- Data Science | Machine Learning\n\n\nContact\n\nemail: 0941813057estifanos@gmail.com\nLinkedIn: profile -tiktok:@tech_guy47"
  },
  {
    "objectID": "projects/Seminar_VAE.html",
    "href": "projects/Seminar_VAE.html",
    "title": "Addisu Amare",
    "section": "",
    "text": "#Variational Autoencoders\nAuthor: Addisu Amare\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nimport torch.utils.data as data\n\nfrom typing import Tuple\nfrom collections import defaultdict\nassert torch.cuda.is_available()\nDEVICE = 'cuda'\nUSE_CUDA = True"
  },
  {
    "objectID": "projects/Seminar_VAE.html#variational-inference",
    "href": "projects/Seminar_VAE.html#variational-inference",
    "title": "Addisu Amare",
    "section": "1. Variational inference",
    "text": "1. Variational inference\n\n1.1 Problem statement\n\\(\\textbf{Data}\\): $X = {x_{1},‚Ä¶,x_{n}} $ are independent samples \\(D\\)-dimensional samples \\(\\textbf{Task}\\): We solve the task of generative modeling \\(p(X|\\Theta)\\), where \\(\\Theta\\) are parameters of the model.\nWhile we use this model, one can set optimization problem like \\(\\textbf{MLE-problem}\\):\n\\[ \\Theta^{*} = \\arg \\max_{\\Theta}  p(X|\\Theta)\\]\nHowever, one can consider our model like model with \\(d\\)-dimensional latent (hidden) variables \\(Z\\). Thus, having assumed existence of latent codes of our model, we can represent of likelihood as follows:\n\\[ p(X|\\Theta)  = p(X|Z,\\Theta) p(Z|\\Theta) \\]\n\n\\(\\textbf{Importantly}\\), we do this step because we sure, that introduced models might be easily parameterized. For example, like normal distributions:\n\n\\(p(X|Z,\\Theta) = \\mathcal{N}(X| \\mu(Z,\\Theta), \\Sigma^{-1}(Z, \\Theta))\\)\n\\(p(Z|\\Theta) = \\mathcal{N}(Z| \\mu(\\Theta), \\Sigma^{-1}(\\Theta))\\)\n\nThen, our \\(\\textbf{MLE}\\)-problem is the following:\n\\[ \\Theta^{*} = \\arg\\max_{\\Theta}\\prod_{i=1}^{n} p(x_{i}|\\Theta)=  \\arg\\max_{\\Theta}\\prod_{i=1}^{n} \\int_{\\mathbb{R}^{d}} p(x_{i}|Z, \\Theta)p(Z|\\Theta)dZ \\]\n\n\n1.2 Naive approach\nUndoubtedly, this problem might be solved through Monte-Carlo simulation:\n\\[ \\int p(x_{i}|Z,\\Theta)p(Z|\\Theta) dZ = \\mathbb{E}_{\\hat{Z} \\sim p(Z|\\Theta)} p(x_{i}|\\hat{Z},\\Theta) = \\frac{1}{K}\\sum_{k=1}^{K} p(x_{i}|\\hat{Z}_{k},\\Theta) \\]\n\n\\(\\textbf{Challenge}\\): The curse of dimensionality. Namely, we cannot properly cover whole space of \\(p(Z|\\Theta)\\) due to high dimension of the latent code. One can avoid this problem with sampleing more samples, however this amount will grow with increasing of dimensionality of latent code. Thus, to cover the space properly., the number of samples grows exponentially with respect to dimensionality of \\(Z\\). Finally, we cannot make accurate estimation for the integral.\n\\(\\textbf{Another explanation}\\) ‚Ä¶\n\n\n1.3 EM-algorithm\nSince:\n\\[ p(x_{i}|\\Theta) = \\int_{\\mathbb{R}^{d}}p(x_{i}|Z,\\Theta)p(Z|\\Theta)dZ \\]\nThen, we can consider this problem like problem for \\(\\textbf{EM}\\)-algorithm. As far as we know^ \\(\\textbf{E}\\)-step might be solved by two ways:\n\nAccurate Bayesian inference\nMean-field approximation\n\nIn \\(\\textbf{E}\\)-step, we have the following tractable integral that we cannot calculate and as a consequence of that we cannot perform Accurate Bayesian inference.\n\\[ q(Z|x_{i},\\Theta) = \\frac{p(x_{i}|Z,\\Theta) p(Z|\\Theta)}{\\int_{\\mathbb{R}^{d}}p(x_{i}|Z,\\Theta) p(Z|\\Theta)dZ}\\]\nMean-field is sufficnetly difficult for high dimensional latent codes.\n\n\n1.4 Variational Inference\nThen, we move on the Variational Inference:\n\\[ \\sum_{i=1}^{n} \\log p(x_{i}|\\Theta) = \\sum_{i=1}^{n} \\log p(x_{i}|\\Theta) \\int_{\\mathbb{R}^{d}}q(Z)dZ =  \n\\sum_{i=1}^{n} \\int_{\\mathbb{R}^{d}}  \\log p(x_{i}|\\Theta) q(Z)dZ\\]\n\\[\\sum_{i=1}^{n} \\int_{\\mathbb{R}^{d}}  \\log p(x_{i}|\\Theta) q(Z)dZ  =  \\sum_{i=1}^{n} \\int_{\\mathbb{R}^{d}} q(Z)\\log\\frac{p(x_{i},Z|\\Theta)q(Z)}{p(Z|\\Theta,x_{i})q(Z)}dZ = \\]\n\\[ = \\sum_{i=1}^{n} \\int q(Z)\\log\\frac{p(x_{i},Z|\\Theta)}{q(Z)}dZ + \\sum_{i=1}^{n}\\int q(Z)\\log \\frac{q(Z)}{p(Z|x_{i},\\Theta)}dZ\\]\nThe last term is \\(\\textbf{KL}\\)-divergence between our prior knowledge and observed posterior distribution. The main properties of this disctance are:\n\n\\(KL \\geq 0\\)\n\\(KL( \\mathbb{P}|| \\mathbb{Q}) = 0\\) , if \\(\\mathbb{P}=\\mathbb{Q}\\)\n\nFinally, we get \\(\\textbf{ELBO}\\):\n\\[ \\sum_{i=1}^{n} \\log p(x_{i}|\\Theta) \\geq \\sum_{i=1}^{n} \\int q(Z)\\log\\frac{p(x_{i},Z|\\Theta)}{q(Z)}dZ\\]\nIt is worth noticing, that \\(\\textbf{ELBO}\\) has the same formula for optimization like for VAE. We will held maximization for parameters \\(\\Theta\\) and latent distribution \\(q(Z)\\) like in EM-algorithm. Nonetheless, the main distinguish is that likelihood and prior will be constrained by normal distribution during the \\(\\textbf{E}\\)-step.\nThus, we have two models:\n\n\\(p(x_{i},Z|\\Theta)\\) is normal distribution parametrized by NN with parameters \\(\\Theta\\).\n\\(q(Z|x_{i},\\phi)\\) is normal distribution parameterized by NN with parameters \\(\\phi\\).\n\nUndoubtedly, we make more constraints , than we had with acurrate and mean-field solution of EM.\n\\(\\textbf{Our problem with Variational inference}\\):\n\\[ \\sum_{i=1}^{n} \\int_{\\mathbb{R}^{d}} q(Z|x_{i},\\phi) \\log\\frac{p(x_{i},Z|\\Theta)}{q(Z|x_{i},\\phi)}dZ \\to \\max_{\\Theta,\\phi}\\]"
  },
  {
    "objectID": "projects/Seminar_VAE.html#variational-auto-encoders-vae",
    "href": "projects/Seminar_VAE.html#variational-auto-encoders-vae",
    "title": "Addisu Amare",
    "section": "2. Variational Auto Encoders (VAE)",
    "text": "2. Variational Auto Encoders (VAE)\nNow, we make assumption about \\(\\textbf{non-linear}\\) dependence between \\(X\\) and \\(Z\\). Then:\n\n2.1 like M-step:\nour task is maximization during M-step:\n\\[\\sum_{i=1}^{n} \\mathbb{E}_{q(Z|x_{i},\\phi)} \\log p(x_{i},Z|\\Theta) \\to \\max_{\\Theta} \\]\nThen, to calculate this, we need in:\n\nmodel \\(q(Z|x_{i},\\phi)\\) should give us samples\nlogarithm of $ p(x_{i},Z|)$\n\nThen we introduce model $ p(x_{i},Z|)$ as:\n\\[ p(x_{i},Z|\\Theta) = \\mathcal{N}(x_{i}| \\mu(z_{i},\\Theta) , \\sigma^{2}(z_{i},\\Theta)I)*\\mathcal{N}(z_{i}|0,I) \\] \\[p(x_{i},Z|\\Theta) = \\prod_{j=1}^{D}\\mathcal{N}(x_{ij}| \\mu_{j}(z_{i},\\Theta) , \\sigma_{j}^{2}(z_{i},\\Theta))*\\mathcal{N}(z_{i}|0,I) \\]\nThus, the first multiplier is the \\(\\textbf{decoder}\\) :\n\ntakes \\(d\\)-dimensional latent code\noutputs 2\\(D\\)-dimensional vector, where the \\(D\\)-first are means for the corresponding pixel of image, while the second are variances.\n\nAlso, we introduce the following model with ability of sampling latent codes from data sample.\n\\[ q(z|x_{i},\\phi) = \\prod_{j=1}^{d} \\mathcal{N}(z_{j}|m_{j}(x_{i},\\phi),s_{j}^{2}(x_{i},\\phi))\\]\nThis model is the \\(\\textbf{encoder}\\)\n\ntakes \\(D\\)-dimensional sample from data\noutputs 2\\(d\\)-dimensional vector, where the \\(d\\)-first are means for the corresponding latent code, while the second are variances.\n\nIt is worth noticing, that the posterior distribution \\(q(z|x_{i},\\phi)\\). is multiplication of 1-dimensional normal distributions.\n\n\n2.2 like E-step:\nDuring the \\(\\textbf{E}\\)-step, we maximize by parameters of encoder:\nHowever, we know, that the maximization of ELBO corresponds to the minimization of \\(\\textbf{KL}\\)-divergence between prior and current posterior (encoder):\n\\[ KL(q(z_{i}|x_{i},\\phi) || p(z)) \\to \\min_{\\phi}\\]\nYet another reason for choosing normal distribution for \\(q(z_{i}|x_{i},\\phi)\\) is the existence closed form of KL-divergence between gaussian distributions. Thta is why, we pick prior knowledge \\(p(z)\\) as gaussian too."
  },
  {
    "objectID": "projects/Seminar_VAE.html#vae-on-2d-data",
    "href": "projects/Seminar_VAE.html#vae-on-2d-data",
    "title": "Addisu Amare",
    "section": "3. VAE on 2d data",
    "text": "3. VAE on 2d data\nIn this task we will implement simple VAE model for 2d gaussian distribution \\(\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\).\nWe will consider two cases: * 2d univariate distribution (diagonal covariance matrix \\(\\boldsymbol{\\Sigma}\\)); * 2d multivariate distribution (strictly non-diagonal covariance matrix \\(\\boldsymbol{\\Sigma}\\)).\nThe goal is to analyze the difference between these two cases and understand why the trained VAE models will behave differently.\n\n3.1 Data generation\n\nTICKS_FONT_SIZE = 12\nLEGEND_FONT_SIZE = 12\nLABEL_FONT_SIZE = 14\nTITLE_FONT_SIZE = 16\n\n\ndef visualize_2d_data(\n    train_data,test_data,train_labels=None ,\n    test_labels=None ):\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n    ax1.set_title(\"train\", fontsize=TITLE_FONT_SIZE)\n    ax1.scatter(train_data[:, 0], train_data[:, 1], s=1, c=train_labels)\n    ax1.tick_params(labelsize=LABEL_FONT_SIZE)\n    ax2.set_title(\"test\", fontsize=TITLE_FONT_SIZE)\n    ax2.scatter(test_data[:, 0], test_data[:, 1], s=1, c=test_labels)\n    ax2.tick_params(labelsize=LABEL_FONT_SIZE)\n    plt.show()\n\n\ndef visualize_2d_samples(data, title, labels=None, xlabel=None, ylabel=None):\n    plt.figure(figsize=(5, 5))\n    plt.scatter(data[:, 0], data[:, 1], s=1, c=labels)\n    plt.title(title, fontsize=TITLE_FONT_SIZE)\n    plt.xticks(fontsize=TICKS_FONT_SIZE)\n    plt.yticks(fontsize=TICKS_FONT_SIZE)\n    if xlabel is not None:\n        plt.xlabel(xlabel, fontsize=LABEL_FONT_SIZE)\n    if ylabel is not None:\n        plt.ylabel(ylabel, fontsize=LABEL_FONT_SIZE)\n    plt.show()\n\n\ndef generate_2d_data(count, mode='univariate'):\n    assert mode in ['univariate', 'multivariate']\n    np.random.seed(42)\n    mean = [[2.0, 3.0]]\n    sigma = [[3.0, 1.0]]\n    if mode == 'univariate':\n        rotate = [\n            [1.0, 0.0],\n            [0.0, 1.0]\n        ]\n    else:\n        rotate = [\n            [np.sqrt(2) / 2, np.sqrt(2) / 2],\n            [-np.sqrt(2) / 2, np.sqrt(2) / 2]\n        ]\n    data = mean + (np.random.randn(count, 2) * sigma).dot(rotate)\n    data = data.astype('float32')\n    split = int(0.7 * count)\n    train_data, test_data = data[:split], data[split:]\n    return train_data, test_data\n\n\ndef plot_training_curves(train_losses, test_losses, logscale_y=False, logscale_x=False):\n    n_train = len(train_losses[list(train_losses.keys())[0]])\n    n_test = len(test_losses[list(train_losses.keys())[0]])\n    x_train = np.linspace(0, n_test - 1, n_train)\n    x_test = np.arange(n_test)\n\n    plt.figure()\n    for key, value in train_losses.items():\n        plt.plot(x_train, value, label=key + '_train')\n\n    for key, value in test_losses.items():\n        plt.plot(x_test, value, label=key + '_test')\n\n    if logscale_y:\n        plt.semilogy()\n\n    if logscale_x:\n        plt.semilogx()\n\n    plt.legend(fontsize=LEGEND_FONT_SIZE)\n    plt.xlabel('Epoch', fontsize=LABEL_FONT_SIZE)\n    plt.ylabel('Loss', fontsize=LABEL_FONT_SIZE)\n    plt.xticks(fontsize=TICKS_FONT_SIZE)\n    plt.yticks(fontsize=TICKS_FONT_SIZE)\n    plt.grid()\n    plt.show()\n\n\nCOUNT = 15000\n\ntrain_data, test_data = generate_2d_data(COUNT, mode='multivariate')\nvisualize_2d_data(train_data, test_data)\n\ntrain_data, test_data = generate_2d_data(COUNT, mode='univariate')\nvisualize_2d_data(train_data, test_data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe difference of these two cases is the form of covariance matrix \\(\\boldsymbol{\\Sigma}\\).\nIn multivariate case the matrix is non-diagonal, in univariate case it is strictly diagonal. As you will see, our VAE model will have absolutely different results for these datasets.\n\n\n3.2 Kl-divergence and log-likelihood\nNow it is time to define our model. Our model will have the following structure:\n\nThe latent dimensionality is equal to 2, the same as the data dimensionality (\\(\\mathbf{z} \\in \\mathbb{R}^2\\), \\(\\mathbf{x} \\in \\mathbb{R}^2\\)).\nPrior distribution is standard Normal (\\(p(\\mathbf{z}) = \\mathcal{N}(0, I)\\)).\nVariational posterior distribution (or encoder) is \\(q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\mathbf{x}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x}))\\). Here \\(\\boldsymbol{\\phi}\\) denotes all parameters of the encoder neural network.\nGenerative distribution (or decoder) is \\(p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}))\\). Here \\(\\boldsymbol{\\theta}\\) denotes all parameters of the decoder neural network. Please note, that here we will use continuous distribution for our variables \\(\\mathbf{x}\\).\nWe will consider only diagonal covariance matrices \\(\\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x})\\), \\(\\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z})\\).\n\nModel objective is ELBO: \\[\n    \\mathcal{L}(\\boldsymbol{\\phi}, \\boldsymbol{\\theta}) = \\mathbb{E}_{q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})} \\log p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) - KL (q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi}) || p(\\mathbf{z})).\n\\]\nTo make the expectation is independent of parameters \\(\\boldsymbol{\\phi}\\), we will use reparametrization trick.\nTo calculate the loss, we should derive - \\(\\log p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})\\), note that generative distribution is \\(\\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}))\\). - KL between \\(\\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\mathbf{x}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x}))\\) and \\(\\mathcal{N}(0, I)\\).\n\ndef get_normal_KL(mean_1, log_std_1, mean_2=None, log_std_2=None):\n    \"\"\"\n        This function should return the value of KL(p1 || p2),\n        where p1 = Normal(mean_1, exp(log_std_1)), p2 = Normal(mean_2, exp(log_std_2) ** 2).\n        If mean_2 and log_std_2 are None values, we will use standard normal distribution.\n        Note that we consider the case of diagonal covariance matrix.\n    \"\"\"\n    if mean_2 is None:\n        mean_2 = torch.zeros_like(mean_1)\n    if log_std_2 is None:\n        log_std_2 = torch.zeros_like(log_std_1)\n\n    std_1 = torch.exp(log_std_1)\n    std_2 = torch.exp(log_std_2)\n\n    mean_1, mean_2 = mean_1.float(), mean_2.float()\n    std_1 , std_2  = std_1 .float(), std_2 .float()\n\n    p  = torch.distributions.Normal(mean_1, std_1)\n    q  = torch.distributions.Normal(mean_2, std_2)\n    kl = torch.distributions.kl_divergence(p, q)\n\n    return kl\n\n\ndef get_normal_nll(x, mean, log_std):\n    \"\"\"\n        This function should return the negative log likelihood log p(x),\n        where p(x) = Normal(x | mean, exp(log_std) ** 2).\n        Note that we consider the case of diagonal covariance matrix.\n    \"\"\"\n    # ====\n    mean = mean              .float()\n    std  = torch.exp(log_std).float()\n\n    #if (mean.dim() == 0) and (std.dim() == 0):\n    prob = torch.distributions.Normal(mean, std)\n    #else:\n    #    scale_tril=torch.diag(std)\n    #    prob = torch.distributions.MultivariateNormal(mean, scale_tril=scale_tril)\n\n    nnl = -prob.log_prob(x)\n    return nnl\n\n\n\n3.3 VAE\nWe will use simple fully connected dense networks for encoder and decoder.\n\nclass FullyConnectedMLP(nn.Module):\n    def __init__(self, input_shape, hiddens, output_shape):\n        assert isinstance(hiddens, list)\n        super().__init__()\n        self.input_shape  = (input_shape,)\n        self.output_shape = (output_shape,)\n        self.hiddens = hiddens\n\n        model = []\n\n        # ====\n        # your code\n        # stack Dense layers with ReLU activation\n        # note: you do not have to add relu after the last dense layer\n        # ====\n        model.append( nn.Linear(input_shape, hiddens[0]) )\n        model.append( nn.ReLU() )\n\n        for i in range( len(hiddens)-1 ):\n            model.append( nn.Linear(hiddens[i+0], hiddens[i+1]) )\n            model.append( nn.ReLU() )\n\n        model.append( nn.Linear(hiddens[-1], output_shape) )\n        self.net = nn.Sequential(*model)\n\n    def forward(self, x):\n        # ====\n        # your code\n        # apply network that was defined in __init__ and return the output\n        # ====\n        return self.net(x)\n\n\nclass VAE2d(nn.Module):\n    def __init__(self, n_in, n_latent, enc_hidden_sizes, dec_hidden_sizes):\n        assert isinstance(enc_hidden_sizes, list)\n        assert isinstance(dec_hidden_sizes, list)\n        super().__init__()\n        self.n_latent = n_latent\n\n        # ====\n        # your code\n        # define encoder and decoder networks\n        # the encoder takes n_in elements, has enc_hidden_sizes neurons in hidden layers\n        # and outputs 2 * n_latent (n_latent for means, and n_latent for std)\n        # the decoder takes n_latent elements, has dec_hidden_sizes neurons in hidden layers\n        # and outputs 2 * n_in (n_in for means, and n_in for std)\n        # ====\n        self.encoder = FullyConnectedMLP(n_in    , enc_hidden_sizes, 2 * n_latent )\n        self.decoder = FullyConnectedMLP(n_latent, dec_hidden_sizes, 2 * n_in     )\n    def prior(self, n):\n        # ====\n        # your code\n        # return n samples from prior distribution (we use standard normal for prior)\n        # ====\n        loc   = torch.zeros(self.n_latent)\n        scale = torch.ones (self.n_latent)\n        p = torch.distributions.Normal(loc, scale)\n        prior_s = p.sample_n(n)\n\n        if USE_CUDA:\n            prior_s = prior_s.cuda()\n        return prior_s\n\n    def forward(self, x):\n        # ====\n        # your code\n        # now you have to return from the model\n        # - mu_z - means for variational distribution\n        # - mu_x - means for generative distribution\n        # - log_std_z - logarithm of std for variational distribution\n        # - log_std_x - logarithm of std for generative distribution\n        # we use logarithm, since the std is always positive\n        # to get std we will exponentiate it to get rid of this constraint\n\n        # 1) mu_z, log_std_z are outputs from the encoder\n        # 2) apply reparametrization trick to get z (input of decoder)\n        # (do not forget to use self.prior())\n        # 3) mu_x, log_std_x are outputs from the decoder\n        #    Note: [mu, log_std = decoder(input).chunk(2, dim=1)]\n\n        # ====\n        mu_z, log_std_z = self.encoder(x).chunk(2, dim=1)\n        z = torch.exp(log_std_z.to('cuda'))*self.prior( x.size(0) ) + mu_z.to('cuda')\n        mu_x, log_std_x = self.decoder(z).chunk(2, dim=1)\n\n        return mu_z, log_std_z, mu_x, log_std_x\n\n    def loss(self, x):\n        mu_z, log_std_z, mu_x, log_std_x = self(x)\n        # ====\n        # your code\n        # 1) apply model to get mu_z, log_std_z, mu_x, log_std_x\n        # 2) compute reconstruction loss using get_normal_nll (it is the first term in ELBO)\n        # 3) compute KL loss using get_normal_KL (it is the second term in ELBO)\n        # ====\n        recon_loss = torch.sum(get_normal_nll( x, mu_x, log_std_x ))\n        #kl_loss    = torch.sum(get_normal_KL ( mu_z, log_std_z, mu_x, log_std_x ))\n        kl_loss    = torch.sum(get_normal_KL ( mu_z, log_std_z, torch.zeros_like(mu_z), torch.zeros_like(log_std_z) ))\n\n\n        return {\n            'elbo_loss': recon_loss + kl_loss,\n            'recon_loss': recon_loss,\n            'kl_loss': kl_loss\n        }\n\n    def sample(self, n, sample_from_decoder=True):\n        z = None\n        with torch.no_grad():\n            # ====\n            # your code\n            # to sample from VAE model you have to sample from prior\n            # and then apply decoder to prior samples.\n            # parameter noise indicates whether to sample from decoder\n            # or just use means of generative distribution as samples\n            # 1) generate prior samples\n            # 2) apply decoder\n            # 3) sample from the decoder distribution if sample_from_decoder=True\n            # ====\n            prior_s = self.prior(n)\n            mu_x, log_std_x = self.decoder(prior_s).chunk(2, dim=1)\n            if sample_from_decoder:\n                z = torch.exp(log_std_x)*prior_s + mu_x\n            else:\n                z = mu_x\n        return z.cpu().numpy()\n\n\ndef solve_task(train_data, test_data, model, batch_size, epochs, lr, use_cuda=True, use_tqdm=False):\n    train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n    test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE)\n\n    train_losses, test_losses = train_model(\n        model, train_loader, test_loader, epochs=EPOCHS, lr=LR, use_cuda=use_cuda, use_tqdm=use_tqdm, loss_key='elbo_loss'\n    )\n    samples_noise = model.sample(3000, sample_from_decoder=True)\n    samples_nonoise = model.sample(3000, sample_from_decoder=False)\n\n    for key, value in test_losses.items():\n        print('{}: {:.4f}'.format(key, value[-1]))\n\n    plot_training_curves(train_losses, test_losses)\n    visualize_2d_samples(samples_noise, title='Samples with Decoder Noise')\n    visualize_2d_samples(samples_nonoise, title='Samples without Decoder Noise')\n\n\n# ====\n# your code\n# choose these parameters (2 hidden layers could be enough for encoder and decoder)\nENC_HIDDEN_SIZES = [20, 20]\nDEC_HIDDEN_SIZES = [20, 20]\nBATCH_SIZE = 32    # any adequate value\nEPOCHS = 20         # &lt; 10\nLR = 0.001        # &lt; 1e-2\n# ====\n\nCOUNT = 10000\n\n\nfrom tqdm import tqdm\n\n\ndef train_epoch(\n    model: object,\n    train_loader: object,\n    optimizer: object,\n    use_cuda: bool,\n    loss_key: str = \"total\",\n) -&gt; defaultdict:\n    model.train()\n\n    stats = defaultdict(list)\n    for x in tqdm(train_loader):\n        if use_cuda:\n            x = x.cuda()\n        losses = model.loss(x)\n        optimizer.zero_grad()\n        losses[loss_key].backward()\n        optimizer.step()\n\n        for k, v in losses.items():\n            stats[k].append(v.item())\n\n    return stats\n\n\ndef eval_model(model: object, data_loader: object, use_cuda: bool) -&gt; defaultdict:\n    model.eval()\n    stats = defaultdict(float)\n    with torch.no_grad():\n        for x in data_loader:\n            if use_cuda:\n                x = x.cuda()\n            losses = model.loss(x)\n            for k, v in losses.items():\n                stats[k] += v.item() * x.shape[0]\n\n        for k in stats.keys():\n            stats[k] /= len(data_loader.dataset)\n    return stats\n\n\ndef train_model(\n    model: object,\n    train_loader: object,\n    test_loader: object,\n    epochs: int,\n    lr: float,\n    use_tqdm: bool = False,\n    use_cuda: bool = False,\n    loss_key: str = \"total_loss\",\n) -&gt; Tuple[dict, dict]:\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    train_losses = defaultdict(list)\n    test_losses = defaultdict(list)\n    forrange = tqdm(range(epochs)) if use_tqdm else range(epochs)\n    if use_cuda:\n        model = model.cuda()\n\n    for epoch in forrange:\n        model.train()\n        train_loss = train_epoch(model, train_loader, optimizer, use_cuda, loss_key)\n        test_loss = eval_model(model, test_loader, use_cuda)\n\n        for k in train_loss.keys():\n            train_losses[k].extend(train_loss[k])\n            test_losses[k].append(test_loss[k])\n    return dict(train_losses), dict(test_losses)\n\n\ntrain_data, test_data = generate_2d_data(COUNT, mode='multivariate')\nvisualize_2d_data(train_data, test_data)\n\nmodel = VAE2d(2, 2, ENC_HIDDEN_SIZES, DEC_HIDDEN_SIZES).to('cuda')\nsolve_task(train_data, test_data, model, BATCH_SIZE, EPOCHS, LR, use_cuda=True)\n\n\n\n\n\n\n\n\n  0%|          | 0/219 [00:00&lt;?, ?it/s]/tmp/ipython-input-117888137.py:26: FutureWarning: `sample_n(n)` will be deprecated. Use `sample((n,))` instead.\n  prior_s = p.sample_n(n)\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 129.83it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 235.93it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 243.09it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 190.84it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 203.71it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 240.85it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 236.11it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 233.17it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 240.47it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 242.56it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 233.15it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 240.58it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 231.52it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 208.00it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 189.54it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 234.39it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 230.90it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 240.08it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 239.26it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 243.36it/s]\n\n\nelbo_loss: 125.9687\nrecon_loss: 90.7217\nkl_loss: 35.2470\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo analyze our models we will use the following function. Look carefully, do not change.\nThis function calculates the mean \\(\\boldsymbol{\\mu}_{\\boldsymbol{\\phi}}(\\mathbf{x})\\), and covariances \\(\\boldsymbol{\\Sigma}_{\\boldsymbol{\\phi}}(\\mathbf{x})\\) of the variational posterior distribution \\(q(\\mathbf{z} | \\mathbf{x}, \\boldsymbol{\\phi})\\).\n\ndef get_latent_stats(model, test_data, use_cuda=True, batch_size=3000):\n    batch = next(iter(data.DataLoader(test_data, batch_size=batch_size, shuffle=True)))\n    if use_cuda:\n        batch = batch.cuda()\n\n    with torch.no_grad():\n        mu_z, log_std_z = model(batch)[:2]\n\n    mu_z = mu_z.cpu().numpy()\n    std_z = log_std_z.exp().cpu().numpy()\n\n    return mu_z, std_z\n\n\n# just look at these numbers and read the comments after this task\nmu_z, std_z = get_latent_stats(model, test_data, use_cuda=USE_CUDA)\n\nprint('mu_z = ', mu_z.mean(axis=0), '+-', mu_z.std(axis=0))\nprint('std_z = ', std_z.mean(axis=0), '+-', std_z.std(axis=0))\n\nmu_z =  [-0.00333838  0.00629993] +- [0.9503864  0.02816329]\nstd_z =  [0.33444908 0.98905873] +- [0.00776618 0.01851054]\n\n\n/tmp/ipython-input-117888137.py:26: FutureWarning: `sample_n(n)` will be deprecated. Use `sample((n,))` instead.\n  prior_s = p.sample_n(n)\n\n\nSecondly, we will train the VAE model for univariate gaussian distribution.\n\ntrain_data, test_data = generate_2d_data(COUNT, mode='univariate')\nvisualize_2d_data(train_data, test_data)\n\nmodel = VAE2d(2, 2, ENC_HIDDEN_SIZES, DEC_HIDDEN_SIZES).cuda()\nsolve_task(train_data, test_data, model, BATCH_SIZE, EPOCHS, LR, use_cuda=USE_CUDA)\n\n\n\n\n\n\n\n\n  0%|          | 0/219 [00:00&lt;?, ?it/s]/tmp/ipython-input-117888137.py:26: FutureWarning: `sample_n(n)` will be deprecated. Use `sample((n,))` instead.\n  prior_s = p.sample_n(n)\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 230.18it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 235.42it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 235.94it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 204.08it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 184.54it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 237.33it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 239.81it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 235.39it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 238.16it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 233.77it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 243.84it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 240.69it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 239.44it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 233.66it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 187.62it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:01&lt;00:00, 184.49it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 235.14it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 236.41it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 242.78it/s]\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 219/219 [00:00&lt;00:00, 240.52it/s]\n\n\nelbo_loss: 126.0842\nrecon_loss: 125.7401\nkl_loss: 0.3441\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmu_z, std_z = get_latent_stats(model, test_data, use_cuda=USE_CUDA)\n\nprint('mu_z = ', mu_z.mean(axis=0), '+-', mu_z.std(axis=0))\nprint('std_z = ', std_z.mean(axis=0), '+-', std_z.std(axis=0))\n\nmu_z =  [-0.01729548  0.00055771] +- [0.06285747 0.021273  ]\nstd_z =  [1.007619   0.99548346] +- [0.06453445 0.06496055]\n\n\n/tmp/ipython-input-117888137.py:26: FutureWarning: `sample_n(n)` will be deprecated. Use `sample((n,))` instead.\n  prior_s = p.sample_n(n)\n\n\nAfter training the VAE model on these 2 datasets, have a look at ‚ÄúSamples without Decoder Noise‚Äù figures. These figures show the means \\(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z})\\) of the generative distribution \\(p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta})\\). In the case of multivariate gaussian, the means are perfectly aligned with the data distribution. Otherwise, you have to see the strange figure in the univariate gaussian case . This happens due to so called posterior collapse (we will discuss it at the one of our lectures).\nTo be brief, the reason is the following. Our posterior distribution \\(p(\\mathbf{x} | \\mathbf{z}, \\boldsymbol{\\theta}) = \\mathcal{N}(\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{z}), \\boldsymbol{\\Sigma}_{\\boldsymbol{\\theta}}(\\mathbf{z}))\\) is a univariate (covariance matrix is diagonal). Thus, the model does not need latent variable since the data distribution is also univariate. In this case VAE ignores latent variable, cause the model fits the distribution without any information from latent space.\nIf the decoder ignores latent variable, the second term in ELBO (KL) could be low (variational posterior distribution, which is given by encoder model, is close to prior distribution for each datapoint). In the training curves you have to see that KL loss behaves differently in these two cases.\nThe mean and std of variational posterior distribution also proves this concept. For the second case you have to see that mean is almost zero and std is almost one.\nIt is a real problem for generative models and we will discuss later how to overcome it."
  },
  {
    "objectID": "projects/project-example.html",
    "href": "projects/project-example.html",
    "title": "Project Example",
    "section": "",
    "text": "This project focuses on [briefly describe the project, its goals, and significance].\n\n\n\nObjective 1: [Describe the first objective]\nObjective 2: [Describe the second objective]\n\n\n\n\n[Provide a brief overview of the methods used in the project, including any specific techniques or tools.]\n\n\n\n[Summarize the outcomes of the project, including any findings or results.]\n\n\n\n[Discuss any potential future work or next steps related to the project.]\n\n\n\n[Include any references or citations relevant to the project, if applicable.]"
  },
  {
    "objectID": "projects/project-example.html#objectives",
    "href": "projects/project-example.html#objectives",
    "title": "Project Example",
    "section": "",
    "text": "Objective 1: [Describe the first objective]\nObjective 2: [Describe the second objective]"
  },
  {
    "objectID": "projects/project-example.html#methodology",
    "href": "projects/project-example.html#methodology",
    "title": "Project Example",
    "section": "",
    "text": "[Provide a brief overview of the methods used in the project, including any specific techniques or tools.]"
  },
  {
    "objectID": "projects/project-example.html#outcomes",
    "href": "projects/project-example.html#outcomes",
    "title": "Project Example",
    "section": "",
    "text": "[Summarize the outcomes of the project, including any findings or results.]"
  },
  {
    "objectID": "projects/project-example.html#future-work",
    "href": "projects/project-example.html#future-work",
    "title": "Project Example",
    "section": "",
    "text": "[Discuss any potential future work or next steps related to the project.]"
  },
  {
    "objectID": "projects/project-example.html#references",
    "href": "projects/project-example.html#references",
    "title": "Project Example",
    "section": "",
    "text": "[Include any references or citations relevant to the project, if applicable.]"
  },
  {
    "objectID": "Jupyter_note_book.html",
    "href": "Jupyter_note_book.html",
    "title": "Breast Cancer classification Using Machine Learning Classifier",
    "section": "",
    "text": "# import libraries\nimport pandas as pd # for data manupulation or analysis\nimport numpy as np # for numeric calculation\nimport matplotlib.pyplot as plt # for data visualization\nimport seaborn as sns # for data visualization\nimport pickle #for dumping the model or we can use joblib library\n\n\n# Suppressing Warnings\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "Jupyter_note_book.html#create-dataframe",
    "href": "Jupyter_note_book.html#create-dataframe",
    "title": "Breast Cancer classification Using Machine Learning Classifier",
    "section": "Create DataFrame",
    "text": "Create DataFrame\n\n# create datafrmae\ncancer_df = pd.DataFrame(np.c_[cancer_dataset['data'],cancer_dataset['target']],\n             columns = np.append(cancer_dataset['feature_names'], ['target']))\n\n\n# DataFrame to CSV file\ncancer_df.to_csv('breast_cancer_dataframe.csv')\n\n\n# Head of cancer DataFrame\ncancer_df.head(6) \n\n\n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\ntarget\n\n\n\n\n0\n17.99\n10.38\n122.80\n1001.0\n0.11840\n0.27760\n0.3001\n0.14710\n0.2419\n0.07871\n...\n17.33\n184.60\n2019.0\n0.1622\n0.6656\n0.7119\n0.2654\n0.4601\n0.11890\n0.0\n\n\n1\n20.57\n17.77\n132.90\n1326.0\n0.08474\n0.07864\n0.0869\n0.07017\n0.1812\n0.05667\n...\n23.41\n158.80\n1956.0\n0.1238\n0.1866\n0.2416\n0.1860\n0.2750\n0.08902\n0.0\n\n\n2\n19.69\n21.25\n130.00\n1203.0\n0.10960\n0.15990\n0.1974\n0.12790\n0.2069\n0.05999\n...\n25.53\n152.50\n1709.0\n0.1444\n0.4245\n0.4504\n0.2430\n0.3613\n0.08758\n0.0\n\n\n3\n11.42\n20.38\n77.58\n386.1\n0.14250\n0.28390\n0.2414\n0.10520\n0.2597\n0.09744\n...\n26.50\n98.87\n567.7\n0.2098\n0.8663\n0.6869\n0.2575\n0.6638\n0.17300\n0.0\n\n\n4\n20.29\n14.34\n135.10\n1297.0\n0.10030\n0.13280\n0.1980\n0.10430\n0.1809\n0.05883\n...\n16.67\n152.20\n1575.0\n0.1374\n0.2050\n0.4000\n0.1625\n0.2364\n0.07678\n0.0\n\n\n5\n12.45\n15.70\n82.57\n477.1\n0.12780\n0.17000\n0.1578\n0.08089\n0.2087\n0.07613\n...\n23.75\n103.40\n741.6\n0.1791\n0.5249\n0.5355\n0.1741\n0.3985\n0.12440\n0.0\n\n\n\n\n6 rows √ó 31 columns\n\n\n\n\n# Tail of cancer DataFrame\ncancer_df.tail(6) \n\n\n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\ntarget\n\n\n\n\n563\n20.92\n25.09\n143.00\n1347.0\n0.10990\n0.22360\n0.31740\n0.14740\n0.2149\n0.06879\n...\n29.41\n179.10\n1819.0\n0.14070\n0.41860\n0.6599\n0.2542\n0.2929\n0.09873\n0.0\n\n\n564\n21.56\n22.39\n142.00\n1479.0\n0.11100\n0.11590\n0.24390\n0.13890\n0.1726\n0.05623\n...\n26.40\n166.10\n2027.0\n0.14100\n0.21130\n0.4107\n0.2216\n0.2060\n0.07115\n0.0\n\n\n565\n20.13\n28.25\n131.20\n1261.0\n0.09780\n0.10340\n0.14400\n0.09791\n0.1752\n0.05533\n...\n38.25\n155.00\n1731.0\n0.11660\n0.19220\n0.3215\n0.1628\n0.2572\n0.06637\n0.0\n\n\n566\n16.60\n28.08\n108.30\n858.1\n0.08455\n0.10230\n0.09251\n0.05302\n0.1590\n0.05648\n...\n34.12\n126.70\n1124.0\n0.11390\n0.30940\n0.3403\n0.1418\n0.2218\n0.07820\n0.0\n\n\n567\n20.60\n29.33\n140.10\n1265.0\n0.11780\n0.27700\n0.35140\n0.15200\n0.2397\n0.07016\n...\n39.42\n184.60\n1821.0\n0.16500\n0.86810\n0.9387\n0.2650\n0.4087\n0.12400\n0.0\n\n\n568\n7.76\n24.54\n47.92\n181.0\n0.05263\n0.04362\n0.00000\n0.00000\n0.1587\n0.05884\n...\n30.37\n59.16\n268.6\n0.08996\n0.06444\n0.0000\n0.0000\n0.2871\n0.07039\n1.0\n\n\n\n\n6 rows √ó 31 columns\n\n\n\n\n# Information of cancer Dataframe\ncancer_df.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 569 entries, 0 to 568\nData columns (total 31 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   mean radius              569 non-null    float64\n 1   mean texture             569 non-null    float64\n 2   mean perimeter           569 non-null    float64\n 3   mean area                569 non-null    float64\n 4   mean smoothness          569 non-null    float64\n 5   mean compactness         569 non-null    float64\n 6   mean concavity           569 non-null    float64\n 7   mean concave points      569 non-null    float64\n 8   mean symmetry            569 non-null    float64\n 9   mean fractal dimension   569 non-null    float64\n 10  radius error             569 non-null    float64\n 11  texture error            569 non-null    float64\n 12  perimeter error          569 non-null    float64\n 13  area error               569 non-null    float64\n 14  smoothness error         569 non-null    float64\n 15  compactness error        569 non-null    float64\n 16  concavity error          569 non-null    float64\n 17  concave points error     569 non-null    float64\n 18  symmetry error           569 non-null    float64\n 19  fractal dimension error  569 non-null    float64\n 20  worst radius             569 non-null    float64\n 21  worst texture            569 non-null    float64\n 22  worst perimeter          569 non-null    float64\n 23  worst area               569 non-null    float64\n 24  worst smoothness         569 non-null    float64\n 25  worst compactness        569 non-null    float64\n 26  worst concavity          569 non-null    float64\n 27  worst concave points     569 non-null    float64\n 28  worst symmetry           569 non-null    float64\n 29  worst fractal dimension  569 non-null    float64\n 30  target                   569 non-null    float64\ndtypes: float64(31)\nmemory usage: 137.9 KB\n\n\n\n# Numerical distribution of data\ncancer_df.describe() \n\n\n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\ntarget\n\n\n\n\ncount\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n...\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n569.000000\n\n\nmean\n14.127292\n19.289649\n91.969033\n654.889104\n0.096360\n0.104341\n0.088799\n0.048919\n0.181162\n0.062798\n...\n25.677223\n107.261213\n880.583128\n0.132369\n0.254265\n0.272188\n0.114606\n0.290076\n0.083946\n0.627417\n\n\nstd\n3.524049\n4.301036\n24.298981\n351.914129\n0.014064\n0.052813\n0.079720\n0.038803\n0.027414\n0.007060\n...\n6.146258\n33.602542\n569.356993\n0.022832\n0.157336\n0.208624\n0.065732\n0.061867\n0.018061\n0.483918\n\n\nmin\n6.981000\n9.710000\n43.790000\n143.500000\n0.052630\n0.019380\n0.000000\n0.000000\n0.106000\n0.049960\n...\n12.020000\n50.410000\n185.200000\n0.071170\n0.027290\n0.000000\n0.000000\n0.156500\n0.055040\n0.000000\n\n\n25%\n11.700000\n16.170000\n75.170000\n420.300000\n0.086370\n0.064920\n0.029560\n0.020310\n0.161900\n0.057700\n...\n21.080000\n84.110000\n515.300000\n0.116600\n0.147200\n0.114500\n0.064930\n0.250400\n0.071460\n0.000000\n\n\n50%\n13.370000\n18.840000\n86.240000\n551.100000\n0.095870\n0.092630\n0.061540\n0.033500\n0.179200\n0.061540\n...\n25.410000\n97.660000\n686.500000\n0.131300\n0.211900\n0.226700\n0.099930\n0.282200\n0.080040\n1.000000\n\n\n75%\n15.780000\n21.800000\n104.100000\n782.700000\n0.105300\n0.130400\n0.130700\n0.074000\n0.195700\n0.066120\n...\n29.720000\n125.400000\n1084.000000\n0.146000\n0.339100\n0.382900\n0.161400\n0.317900\n0.092080\n1.000000\n\n\nmax\n28.110000\n39.280000\n188.500000\n2501.000000\n0.163400\n0.345400\n0.426800\n0.201200\n0.304000\n0.097440\n...\n49.540000\n251.200000\n4254.000000\n0.222600\n1.058000\n1.252000\n0.291000\n0.663800\n0.207500\n1.000000\n\n\n\n\n8 rows √ó 31 columns\n\n\n\n\ncancer_df.isnull().sum()\n\nmean radius                0\nmean texture               0\nmean perimeter             0\nmean area                  0\nmean smoothness            0\nmean compactness           0\nmean concavity             0\nmean concave points        0\nmean symmetry              0\nmean fractal dimension     0\nradius error               0\ntexture error              0\nperimeter error            0\narea error                 0\nsmoothness error           0\ncompactness error          0\nconcavity error            0\nconcave points error       0\nsymmetry error             0\nfractal dimension error    0\nworst radius               0\nworst texture              0\nworst perimeter            0\nworst area                 0\nworst smoothness           0\nworst compactness          0\nworst concavity            0\nworst concave points       0\nworst symmetry             0\nworst fractal dimension    0\ntarget                     0\ndtype: int64"
  },
  {
    "objectID": "Jupyter_note_book.html#heatmap-of-a-correlation-matrix",
    "href": "Jupyter_note_book.html#heatmap-of-a-correlation-matrix",
    "title": "Breast Cancer classification Using Machine Learning Classifier",
    "section": "Heatmap of a correlation matrix",
    "text": "Heatmap of a correlation matrix\n\ncancer_df.corr()#gives the correlation between them\n\n\n\n\n\n\n\n\nmean radius\nmean texture\nmean perimeter\nmean area\nmean smoothness\nmean compactness\nmean concavity\nmean concave points\nmean symmetry\nmean fractal dimension\n...\nworst texture\nworst perimeter\nworst area\nworst smoothness\nworst compactness\nworst concavity\nworst concave points\nworst symmetry\nworst fractal dimension\ntarget\n\n\n\n\nmean radius\n1.000000\n0.323782\n0.997855\n0.987357\n0.170581\n0.506124\n0.676764\n0.822529\n0.147741\n-0.311631\n...\n0.297008\n0.965137\n0.941082\n0.119616\n0.413463\n0.526911\n0.744214\n0.163953\n0.007066\n-0.730029\n\n\nmean texture\n0.323782\n1.000000\n0.329533\n0.321086\n-0.023389\n0.236702\n0.302418\n0.293464\n0.071401\n-0.076437\n...\n0.912045\n0.358040\n0.343546\n0.077503\n0.277830\n0.301025\n0.295316\n0.105008\n0.119205\n-0.415185\n\n\nmean perimeter\n0.997855\n0.329533\n1.000000\n0.986507\n0.207278\n0.556936\n0.716136\n0.850977\n0.183027\n-0.261477\n...\n0.303038\n0.970387\n0.941550\n0.150549\n0.455774\n0.563879\n0.771241\n0.189115\n0.051019\n-0.742636\n\n\nmean area\n0.987357\n0.321086\n0.986507\n1.000000\n0.177028\n0.498502\n0.685983\n0.823269\n0.151293\n-0.283110\n...\n0.287489\n0.959120\n0.959213\n0.123523\n0.390410\n0.512606\n0.722017\n0.143570\n0.003738\n-0.708984\n\n\nmean smoothness\n0.170581\n-0.023389\n0.207278\n0.177028\n1.000000\n0.659123\n0.521984\n0.553695\n0.557775\n0.584792\n...\n0.036072\n0.238853\n0.206718\n0.805324\n0.472468\n0.434926\n0.503053\n0.394309\n0.499316\n-0.358560\n\n\nmean compactness\n0.506124\n0.236702\n0.556936\n0.498502\n0.659123\n1.000000\n0.883121\n0.831135\n0.602641\n0.565369\n...\n0.248133\n0.590210\n0.509604\n0.565541\n0.865809\n0.816275\n0.815573\n0.510223\n0.687382\n-0.596534\n\n\nmean concavity\n0.676764\n0.302418\n0.716136\n0.685983\n0.521984\n0.883121\n1.000000\n0.921391\n0.500667\n0.336783\n...\n0.299879\n0.729565\n0.675987\n0.448822\n0.754968\n0.884103\n0.861323\n0.409464\n0.514930\n-0.696360\n\n\nmean concave points\n0.822529\n0.293464\n0.850977\n0.823269\n0.553695\n0.831135\n0.921391\n1.000000\n0.462497\n0.166917\n...\n0.292752\n0.855923\n0.809630\n0.452753\n0.667454\n0.752399\n0.910155\n0.375744\n0.368661\n-0.776614\n\n\nmean symmetry\n0.147741\n0.071401\n0.183027\n0.151293\n0.557775\n0.602641\n0.500667\n0.462497\n1.000000\n0.479921\n...\n0.090651\n0.219169\n0.177193\n0.426675\n0.473200\n0.433721\n0.430297\n0.699826\n0.438413\n-0.330499\n\n\nmean fractal dimension\n-0.311631\n-0.076437\n-0.261477\n-0.283110\n0.584792\n0.565369\n0.336783\n0.166917\n0.479921\n1.000000\n...\n-0.051269\n-0.205151\n-0.231854\n0.504942\n0.458798\n0.346234\n0.175325\n0.334019\n0.767297\n0.012838\n\n\nradius error\n0.679090\n0.275869\n0.691765\n0.732562\n0.301467\n0.497473\n0.631925\n0.698050\n0.303379\n0.000111\n...\n0.194799\n0.719684\n0.751548\n0.141919\n0.287103\n0.380585\n0.531062\n0.094543\n0.049559\n-0.567134\n\n\ntexture error\n-0.097317\n0.386358\n-0.086761\n-0.066280\n0.068406\n0.046205\n0.076218\n0.021480\n0.128053\n0.164174\n...\n0.409003\n-0.102242\n-0.083195\n-0.073658\n-0.092439\n-0.068956\n-0.119638\n-0.128215\n-0.045655\n0.008303\n\n\nperimeter error\n0.674172\n0.281673\n0.693135\n0.726628\n0.296092\n0.548905\n0.660391\n0.710650\n0.313893\n0.039830\n...\n0.200371\n0.721031\n0.730713\n0.130054\n0.341919\n0.418899\n0.554897\n0.109930\n0.085433\n-0.556141\n\n\narea error\n0.735864\n0.259845\n0.744983\n0.800086\n0.246552\n0.455653\n0.617427\n0.690299\n0.223970\n-0.090170\n...\n0.196497\n0.761213\n0.811408\n0.125389\n0.283257\n0.385100\n0.538166\n0.074126\n0.017539\n-0.548236\n\n\nsmoothness error\n-0.222600\n0.006614\n-0.202694\n-0.166777\n0.332375\n0.135299\n0.098564\n0.027653\n0.187321\n0.401964\n...\n-0.074743\n-0.217304\n-0.182195\n0.314457\n-0.055558\n-0.058298\n-0.102007\n-0.107342\n0.101480\n0.067016\n\n\ncompactness error\n0.206000\n0.191975\n0.250744\n0.212583\n0.318943\n0.738722\n0.670279\n0.490424\n0.421659\n0.559837\n...\n0.143003\n0.260516\n0.199371\n0.227394\n0.678780\n0.639147\n0.483208\n0.277878\n0.590973\n-0.292999\n\n\nconcavity error\n0.194204\n0.143293\n0.228082\n0.207660\n0.248396\n0.570517\n0.691270\n0.439167\n0.342627\n0.446630\n...\n0.100241\n0.226680\n0.188353\n0.168481\n0.484858\n0.662564\n0.440472\n0.197788\n0.439329\n-0.253730\n\n\nconcave points error\n0.376169\n0.163851\n0.407217\n0.372320\n0.380676\n0.642262\n0.683260\n0.615634\n0.393298\n0.341198\n...\n0.086741\n0.394999\n0.342271\n0.215351\n0.452888\n0.549592\n0.602450\n0.143116\n0.310655\n-0.408042\n\n\nsymmetry error\n-0.104321\n0.009127\n-0.081629\n-0.072497\n0.200774\n0.229977\n0.178009\n0.095351\n0.449137\n0.345007\n...\n-0.077473\n-0.103753\n-0.110343\n-0.012662\n0.060255\n0.037119\n-0.030413\n0.389402\n0.078079\n0.006522\n\n\nfractal dimension error\n-0.042641\n0.054458\n-0.005523\n-0.019887\n0.283607\n0.507318\n0.449301\n0.257584\n0.331786\n0.688132\n...\n-0.003195\n-0.001000\n-0.022736\n0.170568\n0.390159\n0.379975\n0.215204\n0.111094\n0.591328\n-0.077972\n\n\nworst radius\n0.969539\n0.352573\n0.969476\n0.962746\n0.213120\n0.535315\n0.688236\n0.830318\n0.185728\n-0.253691\n...\n0.359921\n0.993708\n0.984015\n0.216574\n0.475820\n0.573975\n0.787424\n0.243529\n0.093492\n-0.776454\n\n\nworst texture\n0.297008\n0.912045\n0.303038\n0.287489\n0.036072\n0.248133\n0.299879\n0.292752\n0.090651\n-0.051269\n...\n1.000000\n0.365098\n0.345842\n0.225429\n0.360832\n0.368366\n0.359755\n0.233027\n0.219122\n-0.456903\n\n\nworst perimeter\n0.965137\n0.358040\n0.970387\n0.959120\n0.238853\n0.590210\n0.729565\n0.855923\n0.219169\n-0.205151\n...\n0.365098\n1.000000\n0.977578\n0.236775\n0.529408\n0.618344\n0.816322\n0.269493\n0.138957\n-0.782914\n\n\nworst area\n0.941082\n0.343546\n0.941550\n0.959213\n0.206718\n0.509604\n0.675987\n0.809630\n0.177193\n-0.231854\n...\n0.345842\n0.977578\n1.000000\n0.209145\n0.438296\n0.543331\n0.747419\n0.209146\n0.079647\n-0.733825\n\n\nworst smoothness\n0.119616\n0.077503\n0.150549\n0.123523\n0.805324\n0.565541\n0.448822\n0.452753\n0.426675\n0.504942\n...\n0.225429\n0.236775\n0.209145\n1.000000\n0.568187\n0.518523\n0.547691\n0.493838\n0.617624\n-0.421465\n\n\nworst compactness\n0.413463\n0.277830\n0.455774\n0.390410\n0.472468\n0.865809\n0.754968\n0.667454\n0.473200\n0.458798\n...\n0.360832\n0.529408\n0.438296\n0.568187\n1.000000\n0.892261\n0.801080\n0.614441\n0.810455\n-0.590998\n\n\nworst concavity\n0.526911\n0.301025\n0.563879\n0.512606\n0.434926\n0.816275\n0.884103\n0.752399\n0.433721\n0.346234\n...\n0.368366\n0.618344\n0.543331\n0.518523\n0.892261\n1.000000\n0.855434\n0.532520\n0.686511\n-0.659610\n\n\nworst concave points\n0.744214\n0.295316\n0.771241\n0.722017\n0.503053\n0.815573\n0.861323\n0.910155\n0.430297\n0.175325\n...\n0.359755\n0.816322\n0.747419\n0.547691\n0.801080\n0.855434\n1.000000\n0.502528\n0.511114\n-0.793566\n\n\nworst symmetry\n0.163953\n0.105008\n0.189115\n0.143570\n0.394309\n0.510223\n0.409464\n0.375744\n0.699826\n0.334019\n...\n0.233027\n0.269493\n0.209146\n0.493838\n0.614441\n0.532520\n0.502528\n1.000000\n0.537848\n-0.416294\n\n\nworst fractal dimension\n0.007066\n0.119205\n0.051019\n0.003738\n0.499316\n0.687382\n0.514930\n0.368661\n0.438413\n0.767297\n...\n0.219122\n0.138957\n0.079647\n0.617624\n0.810455\n0.686511\n0.511114\n0.537848\n1.000000\n-0.323872\n\n\ntarget\n-0.730029\n-0.415185\n-0.742636\n-0.708984\n-0.358560\n-0.596534\n-0.696360\n-0.776614\n-0.330499\n0.012838\n...\n-0.456903\n-0.782914\n-0.733825\n-0.421465\n-0.590998\n-0.659610\n-0.793566\n-0.416294\n-0.323872\n1.000000\n\n\n\n\n31 rows √ó 31 columns"
  },
  {
    "objectID": "Jupyter_note_book.html#suppor-vector-classifier",
    "href": "Jupyter_note_book.html#suppor-vector-classifier",
    "title": "Breast Cancer classification Using Machine Learning Classifier",
    "section": "Suppor vector Classifier",
    "text": "Suppor vector Classifier\n\n# Support vector classifier\nfrom sklearn.svm import SVC\nsvc_classifier = SVC()\nsvc_classifier.fit(X_train, y_train)\ny_pred_scv = svc_classifier.predict(X_test)\naccuracy_score(y_test, y_pred_scv)\n\n0.9385964912280702\n\n\n\nTrain with Standard scaled Data\n\n# Train with Standard scaled Data\nsvc_classifier2 = SVC()\nsvc_classifier2.fit(X_train_sc, y_train)\ny_pred_svc_sc = svc_classifier2.predict(X_test_sc)\naccuracy_score(y_test, y_pred_svc_sc)\n\n0.9649122807017544"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "Scholarship interests\nMy scholarship interests lie at the intersection of data science and biomedical engineering."
  }
]